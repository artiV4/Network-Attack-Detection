{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier # Unsupervised\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# import tensorflow_decision_forests as tfdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorize and enumerate all attacks in dataset\n",
    "ATTACKS = ['DDoS', 'DoS', 'Mirai', 'Recon', 'Spoofing', 'Benign', 'Web', 'BruteForce']\n",
    "ATTACKS_ENUM = Enum('ATTACKS', ATTACKS, start=0)\n",
    "dict_7classes = {}\n",
    "dict_7classes['DDoS-RSTFINFlood'] = 'DDoS'\n",
    "dict_7classes['DDoS-PSHACK_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SYN_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-TCP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SynonymousIP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ACK_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-SlowLoris'] = 'DDoS'\n",
    "dict_7classes['DDoS-HTTP_Flood'] = 'DDoS'\n",
    "\n",
    "dict_7classes['DoS-UDP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-SYN_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-TCP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-HTTP_Flood'] = 'DoS'\n",
    "\n",
    "\n",
    "dict_7classes['Mirai-greeth_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-greip_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-udpplain'] = 'Mirai'\n",
    "\n",
    "dict_7classes['Recon-PingSweep'] = 'Recon'\n",
    "dict_7classes['Recon-OSScan'] = 'Recon'\n",
    "dict_7classes['Recon-PortScan'] = 'Recon'\n",
    "dict_7classes['VulnerabilityScan'] = 'Recon'\n",
    "dict_7classes['Recon-HostDiscovery'] = 'Recon'\n",
    "\n",
    "dict_7classes['DNS_Spoofing'] = 'Spoofing'\n",
    "dict_7classes['MITM-ArpSpoofing'] = 'Spoofing'\n",
    "\n",
    "dict_7classes['BenignTraffic'] = 'Benign'\n",
    "\n",
    "dict_7classes['BrowserHijacking'] = 'Web'\n",
    "dict_7classes['Backdoor_Malware'] = 'Web'\n",
    "dict_7classes['XSS'] = 'Web'\n",
    "dict_7classes['Uploading_Attack'] = 'Web'\n",
    "dict_7classes['SqlInjection'] = 'Web'\n",
    "dict_7classes['CommandInjection'] = 'Web'\n",
    "\n",
    "\n",
    "dict_7classes['DictionaryBruteForce'] = 'BruteForce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Generation of CSV data =====\n",
    "# Adapted from same source as Dataset\n",
    "run_this = False\n",
    "if(run_this):\n",
    "    from pcap2csv import Generating_dataset #Generating_dataset#, Supporting_functions, Communication_features, Connectivity_features, Dynamic_features, Feature_extraction, Layered_features\n",
    "    import os\n",
    "    PCAP_DIRECTORY = 'pcap/'\n",
    "    pcap_files = [k for k in os.listdir(PCAP_DIRECTORY) if k.endswith('.pcap')] \n",
    "    Generating_dataset.make_csv(pcap_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====Split Train / Test data======\n",
    "# Dataset link-> https://www.unb.ca/cic/datasets/iotdataset-2023.html\n",
    "#E. C. P. Neto, S. Dadkhah, R. Ferreira, A. Zohourian, R. Lu, A. A. Ghorbani. \"CICIoT2023: A real-time dataset and benchmark for large-scale attacks in IoT environment,\" Sensor (2023) â€“ (submitted to Journal of Sensors).\n",
    "\n",
    "DATASET_DIRECTORY = 'dataset/'\n",
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')] # all files\n",
    "#df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('1-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')] # smaller subset for faster testing, 17 files =  10% of whole dataset\n",
    "# df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('11-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')] # 2 files = 1%\n",
    "df_sets.sort()\n",
    "training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "test_sets = df_sets[int(len(df_sets)*.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Extract Data=====\n",
    "\n",
    "# === PerFlow ===\n",
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "       'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "       'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "       'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "       'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "       'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "       'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "] #columns 0-45\n",
    "Y_columns = 'label' #column 46\n",
    "\n",
    "# === PerPacket ===\n",
    "# X_columns = [\n",
    "#     'Header_Length', 'Protocol Type', 'Duration',\n",
    "#         'fin_flag_number', 'syn_flag_number',\n",
    "#        'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "#        'ece_flag_number', 'cwr_flag_number', \n",
    "#     'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "#        'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC',\n",
    "# ] #columns 0-45\n",
    "# Y_columns = 'label' #column 46\n",
    "\n",
    "all_columns = X_columns+[Y_columns]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "      'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "      'Rate', 'Srate', 'Drate', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "      'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "      'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "]\n",
    "CATEGORICAL_FEATURE_NAMES = [\n",
    "      'fin_flag_number', 'syn_flag_number',\n",
    "      'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "      'ece_flag_number', 'cwr_flag_number','HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "      'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Feature Scaling======\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler(feature_range=(-1,1)) # for SVC\n",
    "for train_set in tqdm(training_sets):\n",
    "    df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[X_columns]\n",
    "    scaler.fit(df)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, model, name, type, callbacks=None):\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.type = type\n",
    "        self.callbacks = callbacks\n",
    "        #self.batch_size = batch_size\n",
    "\n",
    "TYPES = {}\n",
    "TYPES['SK_LR'] = 1\n",
    "TYPES['SK_RF'] = 2\n",
    "TYPES['SK_SVC'] = 3\n",
    "TYPES['TF'] = 4\n",
    "TYPES['TF_RNN'] = 5\n",
    "TYPES['TF_CNN'] = 6\n",
    "\n",
    "verbose, epochs, batch_size = 0, 10, 64\n",
    "activationFunction='relu'\n",
    "\n",
    "numFeatures=len(X_columns)\n",
    "numClasses=len(ATTACKS)\n",
    "\n",
    "# def getOtimizedSequentialModel():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(46, activation=activationFunction))\n",
    "#     model.add(Dense(30, activation=activationFunction))\n",
    "#     model.add(Dense(8, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return model\n",
    "\n",
    "# def getANN():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(46, activation=activationFunction))\n",
    "#     model.add(Dense(30, activation=activationFunction))\n",
    "#     model.add(Dense(20, activation=activationFunction))\n",
    "#     model.add(Dense(12, activation=activationFunction))\n",
    "#     model.add(Dense(numClasses, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return Model(model, \"ANN\", TYPES['TF'])\n",
    "\n",
    "def getANN():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=numFeatures, activation=activationFunction))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation=activationFunction))\n",
    "    model.add(Dense(32, activation=activationFunction))\n",
    "    model.add(Dense(numClasses, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                    metrics=[ keras.metrics.BinaryAccuracy()]\n",
    "                    )\n",
    "    return Model(model, \"ANN2\", TYPES['TF'])\n",
    "\n",
    "# def getANN3():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(128, input_dim=numFeatures, activation=activationFunction))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(64, activation=activationFunction))\n",
    "#     model.add(Dense(32, activation=activationFunction))\n",
    "#     model.add(Dense(16, activation=activationFunction))\n",
    "#     model.add(Dense(numClasses, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy',\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy()]\n",
    "#                     )\n",
    "#     return Model(model, \"ANN3\", TYPES['TF'])\n",
    "\n",
    "def getRNN():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(numClasses, activation='softmax'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return Model(model, \"RNN\", TYPES['TF_RNN'])\n",
    "\n",
    "def getCNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, kernel_size=1, activation='relu', input_shape=(numFeatures, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(32, kernel_size=1, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(numClasses, activation='softmax'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return Model(model, 'CNN', TYPES['TF_CNN'])\n",
    "\n",
    "# def getCNN2():\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(numFeatures, 1), kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Conv1D(32, kernel_size=3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(numClasses, activation='softmax'))\n",
    "#     model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "#     return Model(model, 'CNN', TYPES['TF_CNN'], [early_stopping])\n",
    "\n",
    "def getRFModel():\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        criterion = 'gini',\n",
    "        max_depth=None,\n",
    "        )\n",
    "    return Model(rf, \"RF\", TYPES['SK_RF'])\n",
    "\n",
    "def getDTModel():\n",
    "    rf = DecisionTreeClassifier(\n",
    "        criterion = 'gini',\n",
    "        max_depth=None,\n",
    "        )\n",
    "    return Model(rf, \"DT\", TYPES['SK_RF'])\n",
    "\n",
    "def getLRModel():\n",
    "    lr = LogisticRegression()\n",
    "    return Model(lr, \"LR\", TYPES['SK_LR'])\n",
    "\n",
    "def getSVCModel():\n",
    "    model = SVC()\n",
    "    return Model(model, \"SVCovr\", TYPES['SK_SVC'])\n",
    "\n",
    "def getovoSVCModel():\n",
    "    model = SVC(decision_function_shape='ovo', verbose=False, cache_size=1000)\n",
    "    return Model(model, \"SVCovo\", TYPES['SK_SVC'])\n",
    "\n",
    "def getLinSVCModel():\n",
    "    model = LinearSVC(tol = 1e-5)\n",
    "    return Model(model, \"Lin-SVC\", TYPES['SK_LR'])\n",
    "\n",
    "def getSGDCModel():\n",
    "    return Model(SGDClassifier(loss='log_loss', penalty='l1', alpha=1e-8, max_iter=3000, tol=1e-5, random_state=11), \"SGDC\", TYPES['SK_LR'])\n",
    "\n",
    "def getKNNCModel():\n",
    "    model = KNeighborsClassifier() # default 5 neighbors\n",
    "    return Model(model, \"KNNC\", TYPES['SK_LR'])\n",
    "\n",
    "def getRadNNCModel():\n",
    "    model = RadiusNeighborsClassifier()\n",
    "    return Model(model, \"RadNNC\", TYPES['SK_LR'])\n",
    "\n",
    "def getNCentModel():\n",
    "    model = NearestCentroid()\n",
    "    return Model(model, \"NCent\", TYPES['SK_LR'])\n",
    "\n",
    "def getRidgeModel():\n",
    "    model = RidgeClassifier(solver='saga')\n",
    "    return Model(model, \"Ridge\", TYPES['SK_RF'])\n",
    "\n",
    "def getBNBModel():\n",
    "    model = BernoulliNB()\n",
    "    return Model(model, \"Bernoulli Naive Bayes\", TYPES['SK_LR'])\n",
    "\n",
    "def getCNBModel():\n",
    "    model = CategoricalNB()\n",
    "    return Model(model, \"Categorical Naive Bayes\", TYPES['SK_LR'])\n",
    "\n",
    "def getGNBModel():\n",
    "    model = GaussianNB()\n",
    "    return Model(model, \"Gausian Naive Bayes\", TYPES['SK_LR'])\n",
    "\n",
    "def getMLPCModel():\n",
    "    model = MLPClassifier() #MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)  \n",
    "    return Model(model, \"MLPC\", TYPES['SK_LR'])\n",
    "\n",
    "def getNUSVCModel():\n",
    "    model = NuSVC()\n",
    "    return Model(model, \"NuSVC\", TYPES['SK_LR'])\n",
    "\n",
    "mod1 = getKNNCModel()\n",
    "mod1.name=\"KNNC2\"\n",
    "mod2 = getKNNCModel()\n",
    "mod2.name=\"KNNC3\"\n",
    "mod3 = getCNN()\n",
    "mod3.name=\"CNN3\"\n",
    "mod4 = getRNN()\n",
    "mod4.name=\"RNN\"\n",
    "mod5 = getSGDCModel()\n",
    "mod5.name=\"SGDC\"\n",
    "ML_Models = [\n",
    "            getSGDCModel()\n",
    "            # mod1,\n",
    "            # mod2,\n",
    "            # mod3,\n",
    "            # mod4,\n",
    "            # mod5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Last ran on {len(ML_Models)} models, with {len(training_sets)} training sets on date: {datetime.datetime.now()}\")\n",
    "for train_set in tqdm(training_sets[:1]):\n",
    "    df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "    x_train = scaler.transform(df[X_columns])\n",
    "    y_train = [ATTACKS_ENUM[dict_7classes[k]].value for k in df[Y_columns]]\n",
    "    y_train_Cat = to_categorical(y_train, num_classes=numClasses)\n",
    "\n",
    "    for i in range(len(ML_Models)):\n",
    "            # print(f\"model{i}\")\n",
    "            model = ML_Models[i]\n",
    "            if model.type==TYPES[\"SK_LR\"]:\n",
    "                model.model.fit(x_train, y_train)  \n",
    "            \n",
    "            if model.type==TYPES[\"SK_SVC\"]:\n",
    "                length = len(x_train) \n",
    "                print(length)\n",
    "                slicesize = length//8\n",
    "                for j in range(0, length, slicesize):\n",
    "                    curr_x_train = x_train[j:j+slicesize]\n",
    "                    curr_y_train = y_train[j:j+slicesize]\n",
    "                    print(f\"training on {j}\")\n",
    "                    model.model.fit(curr_x_train, curr_y_train)\n",
    "                del curr_x_train\n",
    "\n",
    "            elif model.type==TYPES[\"SK_RF\"]:\n",
    "                model.model.fit(x_train, y_train_Cat)  \n",
    "\n",
    "            elif model.type == TYPES[\"TF\"]:\n",
    "                model.model.fit(x=x_train, \n",
    "                            y=y_train_Cat, \n",
    "                            epochs=epochs, \n",
    "                            verbose=verbose,\n",
    "                            batch_size=batch_size) \n",
    "\n",
    "            elif model.type == TYPES['TF_RNN']: \n",
    "                curr_x_train= np.reshape(x_train, (x_train.shape[0], 1, numFeatures))\n",
    "                model.model.fit(x=curr_x_train, \n",
    "                            y=y_train_Cat, \n",
    "                            epochs=epochs, \n",
    "                            verbose=verbose,\n",
    "                            batch_size=batch_size) \n",
    "                del curr_x_train\n",
    "\n",
    "            elif model.type == TYPES['TF_CNN']: \n",
    "                curr_x_train= np.reshape(x_train, (x_train.shape[0], numFeatures, 1))\n",
    "                model.model.fit(x=curr_x_train, \n",
    "                            y=y_train_Cat, \n",
    "                            epochs=epochs, \n",
    "                            verbose=verbose,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=model.callbacks\n",
    "                            )    \n",
    "                del curr_x_train         \n",
    "    del df\n",
    "    del x_train\n",
    "    del y_train\n",
    "    del y_train_Cat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the resulting trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResults(test, pred,model_name):\n",
    "    output = ''\n",
    "    output += str(datetime.datetime.now())\n",
    "    output += f\"\\n===== {model_name} =====\\n\"\n",
    "    output+=classification_report(test, pred, target_names=ATTACKS)\n",
    "    accuracy = accuracy_score(test, pred)\n",
    "    precision=precision_score(test, pred, average='weighted')\n",
    "    f1Score=f1_score(test, pred, average='weighted') \n",
    "    output+=f\"\\nAccuracy  : {accuracy}\\n\"\n",
    "    output+=f\"Precision : {precision}\\n\"\n",
    "    output+=f\"f1Score : {f1Score}\\n\"\n",
    "    cm=confusion_matrix(test, pred)\n",
    "    output+=str(cm) \n",
    "    \n",
    "    joblib.dump(output, f\"outputs/{model_name}.txt\", protocol=1) \n",
    "\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model):\n",
    "    y_test = []\n",
    "    y_predict = []\n",
    "    for test_set in tqdm(test_sets):\n",
    "        df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "        x_test = scaler.transform(df[X_columns])\n",
    "        for k in df[Y_columns]:\n",
    "            y_test.append(ATTACKS_ENUM[dict_7classes[k]].value)\n",
    "        if model.type == TYPES['TF'] or model.type==TYPES['TF_CNN']:\n",
    "            y_predict+= list(model.model.predict(x_test, verbose=0))\n",
    "        elif model.type== TYPES[\"TF_RNN\"]:\n",
    "            x_test= np.reshape(x_test, (x_test.shape[0], 1, numFeatures))\n",
    "            y_predict+= list(model.model.predict(x_test, verbose=0))\n",
    "        elif model.type==TYPES[\"SK_SVC\"]:\n",
    "            length = len(x_test) \n",
    "            print(length)\n",
    "            slicesize = length//8\n",
    "            for j in range(0, length, slicesize):\n",
    "                curr_x_test = x_test[j:j+slicesize]\n",
    "                print(f\"testing on {j}\")\n",
    "                y_predict+= list(model.model.predict(curr_x_test))\n",
    "        else:\n",
    "            y_predict+= list(model.model.predict(x_test))\n",
    "\n",
    "        del df\n",
    "        del x_test\n",
    "\n",
    "    y_test=np.array(y_test)\n",
    "    if model.type == TYPES['TF'] or model.type ==TYPES[\"SK_RF\"] or model.type==TYPES[\"TF_RNN\"] or model.type==TYPES['TF_CNN']:\n",
    "        y_test = to_categorical(y_test, num_classes=8)\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "        y_predict = np.argmax(y_predict, axis=1)\n",
    "    showResults(y_test, y_predict, model.name)\n",
    "\n",
    "\n",
    "    del y_test\n",
    "    del y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for timing, remove file i/o times\n",
    "def onlyPredict(model):\n",
    "    y_test = []\n",
    "    y_predict = []\n",
    "    for test_set in tqdm(test_sets):\n",
    "        df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "        x_test = scaler.transform(df[X_columns])\n",
    "        for k in df[Y_columns]:\n",
    "            y_test.append(ATTACKS_ENUM[dict_7classes[k]].value)\n",
    "        if model.type == TYPES['TF'] or model.type==TYPES['TF_CNN']:\n",
    "            y_predict+= list(model.model.predict(x_test, verbose=0))\n",
    "        elif model.type== TYPES[\"TF_RNN\"]:\n",
    "            x_test= np.reshape(x_test, (x_test.shape[0], 1, numFeatures))\n",
    "            y_predict+= list(model.model.predict(x_test, verbose=0))\n",
    "        elif model.type==TYPES[\"SK_SVC\"]:\n",
    "            length = len(x_test) \n",
    "            print(length)\n",
    "            slicesize = length//8\n",
    "            for j in range(0, length, slicesize):\n",
    "                curr_x_test = x_test[j:j+slicesize]\n",
    "                print(f\"testing on {j}\")\n",
    "                y_predict+= list(model.model.predict(curr_x_test))\n",
    "        else:\n",
    "            y_predict+= list(model.model.predict(x_test))\n",
    "\n",
    "        del df\n",
    "        del x_test\n",
    "\n",
    "    y_test=np.array(y_test)\n",
    "    if model.type == TYPES['TF'] or model.type ==TYPES[\"SK_RF\"] or model.type==TYPES[\"TF_RNN\"] or model.type==TYPES['TF_CNN']:\n",
    "        y_test = to_categorical(y_test, num_classes=8)\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "        y_predict = np.argmax(y_predict, axis=1)\n",
    "\n",
    "\n",
    "    del y_test\n",
    "    del y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for graphing model\n",
    "# def getBinary(test, pred):\n",
    "#     return test != ATTACKS_ENUM[dict_7classes[\"BenignTraffic\"]].value, pred != ATTACKS_ENUM[dict_7classes[\"BenignTraffic\"]].value\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "def getROC(model):\n",
    "    y_test = []\n",
    "    y_predict = []\n",
    "    for test_set in tqdm(test_sets):\n",
    "        df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "        x_test = scaler.transform(df[X_columns])\n",
    "        for k in df[Y_columns]:\n",
    "            y_test.append(ATTACKS_ENUM[dict_7classes[k]].value)\n",
    "        if model.type == TYPES['TF'] or model.type==TYPES['TF_CNN']:\n",
    "            y_predict+= list(model.model.predict(x_test, verbose=0))\n",
    "        elif model.type== TYPES[\"TF_RNN\"]:\n",
    "            x_test= np.reshape(x_test, (x_test.shape[0], 1, numFeatures))\n",
    "            y_predict+= list(model.model.predict(x_test, verbose=0))\n",
    "        elif model.type==TYPES[\"SK_SVC\"]:\n",
    "            length = len(x_test) \n",
    "            print(length)\n",
    "            slicesize = length//8\n",
    "            for j in range(0, length, slicesize):\n",
    "                curr_x_test = x_test[j:j+slicesize]\n",
    "                print(f\"testing on {j}\")\n",
    "                y_predict+= list(model.model.decision_function(curr_x_test))\n",
    "        elif(model.name==\"Lin-SVC\"):\n",
    "            y_predict+= list(model.model.decision_function(x_test))\n",
    "        elif(model.type == TYPES[\"SK_RF\"]):\n",
    "            # DT and RF were trained a bit differently, so they can only predict with 100% certainty for now\n",
    "            y_predict += list(model.model.predict(x_test))\n",
    "        else:\n",
    "            y_predict+= list(model.model.predict_proba(x_test))\n",
    "        # return\n",
    "        del df\n",
    "        del x_test\n",
    "    \n",
    "    # SGD outputs NaN sometimes for predict_proba because it does prob/=prob.sum(...) = 0/0\n",
    "    # known error, couldn't find fix\n",
    "    # https://github.com/scikit-learn/scikit-learn/pull/18015\n",
    "    # So I'm deleting NaN datapoints instead of fixing root issue\n",
    "    if(model.name[:4]==\"SGDC\"):\n",
    "        new_y_pred = []\n",
    "        new_y_test = []\n",
    "        for i in range(len(y_predict)):\n",
    "            if not np.isnan(np.sum(y_predict[i])):\n",
    "\n",
    "                new_y_pred+=list(y_predict[i])\n",
    "                new_y_test.append(y_test[i])\n",
    "        y_predict=new_y_pred\n",
    "        y_test=new_y_test\n",
    "    y_predict = np.array(y_predict)\n",
    "    y_test=np.array(y_test)\n",
    "    label_binarizer.fit(y_test)\n",
    "    y_onehot_test = label_binarizer.transform(y_test)\n",
    "    \n",
    "    return y_onehot_test, y_predict\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ML_Models)):\n",
    "    model = ML_Models[i]\n",
    "    if model.type==TYPES[\"TF\"]:# or model.type==TYPES['TF_CNN'] or model.type==TYPES['TF_RNN']:\n",
    "        model.model.save(f\"SavedModels\\\\{model.name}.keras\",overwrite=True)\n",
    "    else:\n",
    "        joblib.dump(model.model, f\"SavedModels/{model.name}.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Last ran on {len(ML_Models)} models, with {len(test_sets)} testing sets on date: {datetime.datetime.now()}\")\n",
    "# temp_df_sets=[k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "# test_sets=temp_df_sets[int(len(temp_df_sets)*.8):]\n",
    "for i in range(len(ML_Models)):\n",
    "    testModel(ML_Models[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import process_time_ns\n",
    "\n",
    "# test_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')] \n",
    "folder = 'SavedModels/PerFlow/'\n",
    "Models = [\"ANN1.keras\", \"RNN.pkl\", 'CNN1.pkl', 'DT.pkl', \"RF1.pkl\", \"KNNC1.pkl\", \"Lin-SVC.pkl\",\"LR.pkl\",\"SGDC.pkl\"] # also test RF from modelTooBig\n",
    "ModelTypes = [\"TF\", \"TF_RNN\", 'TF_CNN', 'SK_RF', \"SK_RF\", \"SK_LR\", \"SK_LR\",\"SK_LR\",\"SK_LR\"]\n",
    "#Models = [\"LR.pkl\"]\n",
    "#ModelTypes = [\"SK_LR\"]\n",
    "\n",
    "# === TIMING ===\n",
    "test_sets = test_sets[:1] # only for timing, remove for graphing\n",
    "df = pd.read_csv(DATASET_DIRECTORY + test_sets[0], index_col=None, header=0, delimiter=',')[all_columns]\n",
    "x_test = scaler.transform(df[X_columns])\n",
    "y_test = (ATTACKS_ENUM[dict_7classes[k]].value for k in df[Y_columns])\n",
    "predictions = len(df)\n",
    "output = f'for {predictions} predictions:\\n'\n",
    "\n",
    "for i in range(len(Models)):\n",
    "    model_name = Models[i].split('.')\n",
    "    if model_name[1] == 'pkl':\n",
    "        model = Model(joblib.load(folder+Models[i]),model_name[0], TYPES[ModelTypes[i]])\n",
    "    elif model_name[1] == 'keras':\n",
    "        model = Model(load_model(folder+Models[i]),model_name[0], TYPES[ModelTypes[i]])\n",
    "    else:\n",
    "        print(f'Error occured at {i} model {Models[i]} type {ModelTypes[i]} : {model_name[0]} - {model.name[1]}')\n",
    "        raise Exception \n",
    "    curr_time = process_time_ns()\n",
    "    onlyPredict(model) \n",
    "    timeTaken = process_time_ns() - curr_time\n",
    "    output += f\"Model {Models[i]} took {timeTaken} ns = {timeTaken/predictions} ns/pred\\n\"\n",
    "joblib.dump(output, f\"outputs/PerPacketTimes.txt\", protocol=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == Remember to check if correct X_columns\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.multiclass import OneVsRestClassifier \n",
    "\n",
    "# test_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')] \n",
    "folder = 'SavedModels/PerFlow/'\n",
    "Models = [\"ANN1.keras\", \"RNN.pkl\", 'CNN1.pkl', 'DT.pkl', \"RF1.pkl\", \"KNNC1.pkl\", \"Lin-SVC.pkl\",\"LR.pkl\",\"SGDC.pkl\"]\n",
    "ModelTypes = [\"TF\", \"TF_RNN\", 'TF_CNN', 'SK_RF', \"SK_RF\", \"SK_LR\", \"SK_LR\",\"SK_LR\",\"SK_LR\"]\n",
    "#Models = [\"LR.pkl\"]\n",
    "#ModelTypes = [\"SK_LR\"]\n",
    "\n",
    "\n",
    "#=== GRAPHING ===\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "for i in range(0, len(Models)):\n",
    "    model_name = Models[i].split('.')\n",
    "    if model_name[1] == 'pkl':\n",
    "        model = Model(joblib.load(folder+Models[i]),model_name[0], TYPES[ModelTypes[i]])\n",
    "    elif model_name[1] == 'keras':\n",
    "        model = Model(load_model(folder+Models[i]),model_name[0], TYPES[ModelTypes[i]])\n",
    "    else:\n",
    "        print(f'Error occured at {i} model {Models[i]} type {ModelTypes[i]} : {model_name[0]} - {model.name[1]}')\n",
    "        raise Exception\n",
    "        \n",
    "    \n",
    "    print(model_name[0])\n",
    "\n",
    "    # try:\n",
    "    y_onehot_test, y_predict = getROC(model)\n",
    "\n",
    "    # print(y_onehot_test.shape)\n",
    "    # print(y_predict.shape)\n",
    "    # print(y_predict[0])\n",
    "    # print(y_onehot_test.ravel().shape)\n",
    "\n",
    "    # class_of_interest = ATTACKS_ENUM['Benign'].value\n",
    "    # display = RocCurveDisplay.from_predictions(\n",
    "    #     y_onehot_test.ravel(),\n",
    "    #     y_predict.ravel(),\n",
    "    #     name=f\"{class_of_interest} vs the rest\",\n",
    "    #     color=\"darkorange\",\n",
    "    #     plot_chance_level=True,\n",
    "    # )\n",
    "    # display.ax_.set(\n",
    "    #     xlabel=\"False Positive Rate\",\n",
    "    #     ylabel=\"True Positive Rate\",\n",
    "    #     title=\"Micro-averaged One-vs-Rest\\nAttack Detection\",\n",
    "    # ) \n",
    "\n",
    "   \n",
    "    print(set(y_predict.ravel()))\n",
    "    fpr, tpr, _ = roc_curve(y_onehot_test.ravel(), y_predict.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name[0]} (area = {roc_auc:.3f})')\n",
    "    \n",
    "    # except Exception as e:\n",
    "    #     print(f\"error at model {i}\")\n",
    "    #     print(e)\n",
    "\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(fname='outputs/PerFlowGraph.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    " # try:\n",
    "        # toDisplay = RocCurveDisplay.from_estimator(model.model, x_test, y_test, name=model_name[0])\n",
    "        # toDisplay.plot()\n",
    "    # except Exception as e:\n",
    "        # print(f\"graphing failed for {model_name[0]}\")\n",
    "        # print(e)\n",
    "    # model.model = OneVsRestClassifier(model.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fpr)\n",
    "print(len(set(tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_datapoints = 0\n",
    "for test_set in test_sets:\n",
    "    df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "    sum_datapoints+=len(df)\n",
    "print(sum_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = [10031250000, 19765625000, 26000000000, 1750000000, 7687500000, 355734375000, 1656250000, 1656250000, 1875000000]\n",
    "# predictions = 269253\n",
    "# for time in times:\n",
    "#     print(f\"{time/predictions},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_results:\n",
    "    def __init__(self, name, accuracy, precision, f1):\n",
    "        self.name = name\n",
    "        self.accuracy = accuracy\n",
    "        self.acc_avg = sum(accuracy)/len(accuracy) * 100\n",
    "        self.precision = precision\n",
    "        self.prec_avg = sum(precision)/len(precision) * 100\n",
    "        self.f1 = f1\n",
    "        self.f1_avg = sum(f1)/len(f1) * 100\n",
    "\n",
    "resultsPerPacket = []\n",
    "# === PerPacket ===\n",
    "resultsPerPacket.append(model_results(\"ANN\", \n",
    "                             [0.8363423935081862, 0.8189355078707189, 0.8360923974007755], \n",
    "                             [0.8242813893762964, 0.7930755803831608, 0.8264773518966853],\n",
    "                             [0.8033314280507646, 0.7704990399217961, 0.8007358074495404]))\n",
    "resultsPerPacket.append(model_results(\"CNN\", \n",
    "                             [0.828229560448817, 0.8116027400347054, 0.8105641681981548], \n",
    "                             [0.8377076880563963, 0.7851717480546523, 0.7773409906723195],\n",
    "                             [0.7769779968512212, 0.7445170728149125, 0.7449511561466423]))\n",
    "resultsPerPacket.append(model_results(\"DT\", \n",
    "                             [0.8617882255411691], \n",
    "                             [0.8564233611567722],\n",
    "                             [0.8582112668335136]))\n",
    "\n",
    "resultsPerPacket.append(model_results(\"KNNC\", \n",
    "                             [0.8653204722827816,0.8653204722827816,0.8653204722827816], \n",
    "                             [0.8582076734243121,0.8582076734243121,0.8582076734243121],\n",
    "                             [0.8602734859584316, 0.8602734859584316,0.8602734859584316]))\n",
    "\n",
    "resultsPerPacket.append(model_results(\"Lin-SVC\", \n",
    "                             [0.7990202473636532], \n",
    "                             [0.7360296695982713],\n",
    "                             [0.7205289617679674]))\n",
    "\n",
    "\n",
    "resultsPerPacket.append(model_results(\"LR\", \n",
    "                             [0.805402353019455], \n",
    "                             [0.7596829533364038],\n",
    "                             [0.7355421024096104]))\n",
    "\n",
    "resultsPerPacket.append(model_results(\"RF\", \n",
    "                             [0.8671398830250322,0.8672330150371933,0.8671038100857423], \n",
    "                             [0.8602387055785887,0.8603159380506288,0.8601849251027491],\n",
    "                             [0.8618976996130436,0.8620041671283907,0.8618578937212659]))\n",
    "\n",
    "resultsPerPacket.append(model_results(\"RNN\", \n",
    "                             [0.8391164315526615], \n",
    "                             [0.8320809279562782],\n",
    "                             [0.8039819651087701]))\n",
    "\n",
    "resultsPerPacket.append(model_results(\"SGDC\", \n",
    "                             [0.7491903656045588], \n",
    "                             [0.7651089288249903],\n",
    "                             [0.7522664614731994]))\n",
    "\n",
    "\n",
    "resultsPerFlow = []\n",
    "resultsPerFlow.append(model_results(\"ANN\", \n",
    "                             [0.8980204466835671, 0.9897758845340996, 0.9901803269794348], \n",
    "                             [0.9295431281392179, 0.9888539062611567, 0.9894651547332924],\n",
    "                             [0.9042644801047449, 0.9890495496217642, 0.9895601306618789]))\n",
    "\n",
    "resultsPerFlow.append(model_results(\"CNN\", \n",
    "                             [0.9587012233175093, 0.9582944598251419, 0.9828162250084888], \n",
    "                             [0.9633181124042057, 0.9641698858143064, 0.9835770658807919],\n",
    "                             [0.9575811933769967, 0.9569877704039879, 0.9806759958921172]))\n",
    "\n",
    "resultsPerFlow.append(model_results(\"DT\", \n",
    "                             [0.9938437128783585], \n",
    "                             [0.9938571777665077],\n",
    "                             [0.9938480082668094]))\n",
    "\n",
    "resultsPerFlow.append(model_results(\"KNNC\", \n",
    "                             [0.9470609790311776, 0.9470609790311776, 0.9470609790311776], \n",
    "                             [0.9459529861827173, 0.9459529861827173, 0.9459529861827173],\n",
    "                             [0.9460690520641846, 0.9460690520641846, 0.9460690520641846]))\n",
    "\n",
    "resultsPerFlow.append(model_results(\"Lin-SVC\", \n",
    "                             [0.8251153923038529], \n",
    "                             [0.8105785696249442],\n",
    "                             [0.7725492921047848]))\n",
    "\n",
    "resultsPerFlow.append(model_results(\"LR\", \n",
    "                             [0.8316742843752626], \n",
    "                             [0.8220156640220578],\n",
    "                             [0.7853791074821646]))\n",
    "\n",
    "resultsPerFlow.append(model_results(\"RF\", \n",
    "                             [0.991719374582272, 0.9918904550905929, 0.9919651154367906], \n",
    "                             [0.991391416107968, 0.9916237016604927, 0.9914063587149685],\n",
    "                             [0.990869295834786, 0.991074670013465, 0.9911420457087886]))\n",
    "\n",
    "resultsPerFlow.append(model_results(\"RNN\", \n",
    "                             [0.9919436457517441], \n",
    "                             [0.9918803825902216],\n",
    "                             [0.9914553675687228]))\n",
    "\n",
    "resultsPerFlow.append(model_results(\"SGDC\", \n",
    "                             [0.8464756012986645], \n",
    "                             [0.8545348880290421],\n",
    "                             [0.8471558640621556]))\n",
    "\n",
    "\n",
    "print(f\"avg ANN {resultsPerFlow[0].acc_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "br1 = np.arange(len(resultsPerPacket))\n",
    "br2 = [i + width for i in br1] \n",
    "br3 = [i + width for i in br2] \n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "for result in resultsPerPacket:\n",
    "    names.append(result.name)\n",
    "    accuracies.append(result.acc_avg)\n",
    "    precisions.append(result.prec_avg)\n",
    "    f1s.append(result.f1_avg)\n",
    "\n",
    "plt.bar(br1, accuracies, color ='r', width = width, \n",
    "        edgecolor ='grey', label ='Accuracy') \n",
    "plt.bar(br2, precisions, color ='g', width = width, \n",
    "        edgecolor ='grey', label ='Precision') \n",
    "plt.bar(br3, f1s, color ='b', width = width, \n",
    "        edgecolor ='grey', label ='f1 score') \n",
    "\n",
    "plt.xlabel('Model', fontweight ='bold', fontsize = 15) \n",
    "plt.ylabel('Score (%)', fontweight ='bold', fontsize = 15) \n",
    "plt.xticks([r + width for r in range(len(names))], \n",
    "        names)\n",
    "ax.set_ylim(50, 100)\n",
    "plt.legend()\n",
    "plt.savefig(fname='outputs/PerPacketBarPlot2.png')\n",
    "plt.show() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "names = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "br1 = np.arange(len(resultsPerFlow))\n",
    "br2 = [i + width for i in br1] \n",
    "br3 = [i + width for i in br2] \n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "for result in resultsPerFlow:\n",
    "    names.append(result.name)\n",
    "    accuracies.append(result.acc_avg)\n",
    "    precisions.append(result.prec_avg)\n",
    "    f1s.append(result.f1_avg)\n",
    "\n",
    "plt.bar(br1, accuracies, color ='r', width = width, \n",
    "        edgecolor ='grey', label ='Accuracy') \n",
    "plt.bar(br2, precisions, color ='g', width = width, \n",
    "        edgecolor ='grey', label ='Precision') \n",
    "plt.bar(br3, f1s, color ='b', width = width, \n",
    "        edgecolor ='grey', label ='f1 score') \n",
    "\n",
    "plt.xlabel('Model', fontweight ='bold', fontsize = 15) \n",
    "plt.ylabel('Score (%)', fontweight ='bold', fontsize = 15) \n",
    "plt.xticks([r + width for r in range(len(names))], \n",
    "        names)\n",
    "ax.set_ylim(0, 100)\n",
    "plt.legend()\n",
    "plt.savefig(fname='outputs/PerFlowBarPlot2.png')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = joblib.load('SavedModels/PerFlow/DT.pkl')\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "features = X_columns\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='g', align='center')\n",
    "plt.yticks(fontsize=6)\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xticks(np.arange(min(importances), max(importances)+0.01, 0.05))\n",
    "plt.xlabel('Relative Importance')\n",
    "# plt.savefig(fname='outputs/PerPacketRFFeatureImportance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "timingsPerPacket = [37255.85230248131,\n",
    "73409.11707576146,\n",
    "96563.45518898583,\n",
    "6499.463330027892,\n",
    "28551.213914051095,\n",
    "1321190.0145959377,\n",
    "6151.277794490684,\n",
    "6151.277794490684,\n",
    "6963.71071074417] # ns/pred \n",
    "\n",
    "timingsPerFlow = [46116.68749973871,\n",
    "                  77470.80931259223,\n",
    "                  109739.42634498731,\n",
    "                  8165.135888763937,\n",
    "                  31027.51637730296,\n",
    "                  1583709.7569846532,\n",
    "                  6140.182188350481,\n",
    "                  6270.824362570704,\n",
    "                  5486.971317249366]\n",
    "\n",
    "models = [\"ANN\", \"RNN\", \"CNN\", \"DT\", \"RF\", \"KNNC\", \"Lin-SVC\", \"LR\", \"SGDC\"]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Model Prediction Timing perPacket')\n",
    "plt.barh(range(len(timingsPerPacket)), timingsPerPacket, color='g', align='center')\n",
    "plt.yticks(fontsize=6)\n",
    "plt.yticks(range(len(models)), models)\n",
    "plt.xscale('log')\n",
    "# plt.xticks(np.arange(min(timingsPerPacket), max(timingsPerPacket), 0.05))\n",
    "plt.xlabel('ns / prediction')\n",
    "plt.savefig(fname='outputs/PerPacketTiming.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Model Prediction Timing perFlow')\n",
    "plt.barh(range(len(timingsPerFlow)), timingsPerFlow, color='g', align='center')\n",
    "plt.yticks(fontsize=6)\n",
    "plt.yticks(range(len(models)), models)\n",
    "plt.xscale('log')\n",
    "# plt.xticks(np.arange(min(timingsPerPacket), max(timingsPerPacket), 0.05))\n",
    "plt.xlabel('ns / prediction')\n",
    "plt.savefig(fname='outputs/PerFlowTiming.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {\n",
    "#     # 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "#     'loss': ['log_loss'],\n",
    "#     'penalty': ['l2', 'l1'],\n",
    "#     # 'penalty': ['l2'],\n",
    "#     'alpha': [1e-10, 1e-9, 1e-8, 1e-7],\n",
    "#     'max_iter': [1000],\n",
    "#     'tol': [1e-5]\n",
    "# }\n",
    "# grid_search = GridSearchCV(SGDClassifier(), param_grid, scoring='accuracy', n_jobs=-1)\n",
    "# print(f\"Last ran on grid, with {len(training_sets)} training sets on date: {datetime.datetime.now()}\")\n",
    "# for train_set in tqdm(training_sets):\n",
    "#     df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#     x_train = scaler.transform(df[X_columns])\n",
    "#     y_train = [ATTACKS_ENUM[dict_7classes[k]].value for k in df[Y_columns]]\n",
    "\n",
    "#     grid_search.fit(x_train, y_train)                   \n",
    "#     del df\n",
    "#     del x_train\n",
    "#     del y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "# print(\"Best Parameters:\", best_params)\n",
    "# testModel(Model(best_model, \"SGDC FromGrid\", TYPES[\"SK_LR\"]))\n",
    "# # print(\"Best Model Accuracy:\", best_model.score(x_test, y_test))\n",
    "# # print(\"Best Model Classification Report:\\n\", classification_report(y_test, best_model.predict(X_test)))\n",
    "# # print(\"Best Model Confusion Matrix:\\n\", confusion_matrix(y_test, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====For debug ===\n",
    "# test_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')] \n",
    "#testModel(Model(load_model(\"SavedModels\\\\BestANN.keras\"),\"BestANN\", TYPES['TF']))\n",
    "# testModel(Model(joblib.load(\"SavedModels/BestRF.pkl\"),\"BestRF\", TYPES['SK_RF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = getSimpleRFModel()\n",
    "# num_sample = 10\n",
    "# for train_set in tqdm(training_sets):\n",
    "#     df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#     df = df[0:num_sample]\n",
    "#     x_train = scaler.transform(df[X_columns])\n",
    "#     y_train = [ATTACKS_ENUM[dict_7classes[k]].value for k in df[Y_columns]]\n",
    "#     y_train_Cat = to_categorical(y_train, num_classes=8)\n",
    "\n",
    "    \n",
    "#     if model.type==TYPES[\"SK_LR\"]:\n",
    "#         model.model.fit(x_train, y_train)  \n",
    "    \n",
    "#     elif model.type==TYPES[\"SK_RF\"]:\n",
    "#         model.model.fit(x_train, y_train_Cat)  \n",
    "\n",
    "#     elif model.type == TYPES[\"TF\"]:\n",
    "#         model.model.fit(x=x_train, \n",
    "#                     y=y_train_Cat, \n",
    "#                     epochs=epochs, \n",
    "#                     verbose=verbose,\n",
    "#                     batch_size=batch_size)                   \n",
    "#     del df\n",
    "#     del x_train\n",
    "#     del y_train\n",
    "#     del y_train_Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tree Visualisation\n",
    "# from sklearn.tree import export_graphviz\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn import tree\n",
    "# rf = joblib.load(\"SavedModels/BestRF.pkl\")\n",
    "# for tree_in_rf in rf:\n",
    "#     fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
    "#     # export_graphviz(tree,\n",
    "#     #             feature_names=X_columns,\n",
    "#     #             class_names=ATTACKS,\n",
    "#     #             filled=True,\n",
    "#     #             rounded=True)\n",
    "#     tree.plot_tree(rf.estimators_[0],\n",
    "#                 feature_names=X_columns,\n",
    "#                 class_names=ATTACKS,\n",
    "#                filled = True)\n",
    "#     fig.savefig(f'rf_{i}.png')\n",
    "#     i+=1\n",
    "# for tree_in_rf in rf[:1]:\n",
    "#     export_graphviz(tree_in_rf,\n",
    "#                 feature_names=X_columns,\n",
    "#                 class_names=ATTACKS,\n",
    "#                 filled=True,\n",
    "#                 rounded=True,\n",
    "#                 out_file=\"tree.png\")\n",
    "#     os.system(\"-Tpng tree.dot -o tree.png\")\n",
    "# fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
    "# tree.plot_tree(model.model.estimators_[0])#,\n",
    "#             # feature_names=X_columns,\n",
    "#             # class_names=ATTACKS,\n",
    "#             # filled = True)\n",
    "# fig.savefig(f'rf_{num_sample}_samples.png')\n",
    "\n",
    "\n",
    "\n",
    "# # == Feature importance for RF and DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(ML_Models)):\n",
    "#     model = ML_Models[i]\n",
    "#     if model.type==TYPES[\"TF\"]:\n",
    "#         model.model.save(f\"SavedModels\\\\{model.name}.keras\",overwrite=True)\n",
    "#     elif model.type==TYPES[\"SK_RF\"] or model.type==TYPES[\"SK_LR\"]:\n",
    "#         joblib.dump(model.model, f\"SavedModels/{model.name}.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a seperate model to detect each attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose, epochs, batch_size = 1, 100, 512\n",
    "# activationFunction='relu'\n",
    "\n",
    "# def getSequentialModel():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(128, activation=activationFunction))\n",
    "#     model.add(Dense(64, activation=activationFunction))\n",
    "#     model.add(Dense(32, activation=activationFunction))\n",
    "#     model.add(Dense(16, activation=activationFunction))\n",
    "#     model.add(Dense(8, activation=activationFunction))\n",
    "#     model.add(Dense(4, activation=activationFunction))\n",
    "#     model.add(Dense(2, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return model\n",
    "\n",
    "# ML_Models = [\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel()\n",
    "\n",
    "# ]\n",
    "# ML_Model_Names = ATTACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Last ran on {len(ML_Models)} models, with {len(training_sets)} training sets on date: {datetime.datetime.now()}\")\n",
    "# for train_set in tqdm(training_sets):\n",
    "#     df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#     x_train = scaler.transform(df[X_columns])\n",
    "\n",
    "#     for i in range(len(ML_Models)-1):\n",
    "#             y_train = to_categorical([ATTACKS_ENUM[dict_7classes[k]].value == ATTACKS_ENUM[ATTACKS[i]].value for k in df[Y_columns]], num_classes=2)\n",
    "#             model = ML_Models[i]\n",
    "#             model.fit(x=x_train, \n",
    "#                         y=y_train, \n",
    "#                         epochs=epochs, \n",
    "#                         verbose=verbose,\n",
    "#                         batch_size=batch_size)   \n",
    "#             del y_train             \n",
    "#     del df\n",
    "#     del x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def showResults8Models(test, pred, model_num):\n",
    "#     print(f\"===== {model_num} =====\")\n",
    "#     print(classification_report(test, pred, target_names=[\"Negative\", \"Positive\"]))\n",
    "#     accuracy = accuracy_score(test, pred)\n",
    "#     precision=precision_score(test, pred, average='weighted')\n",
    "#     f1Score=f1_score(test, pred, average='weighted') \n",
    "#     print(\"Accuracy  : {}\".format(accuracy))\n",
    "#     print(\"Precision : {}\".format(precision))\n",
    "#     print(\"f1Score : {}\".format(f1Score))\n",
    "#     cm=confusion_matrix(test, pred)\n",
    "#     print(cm) \n",
    "\n",
    "# print(f\"Last ran on {len(ML_Models)} models, with {len(test_sets)} testing sets on date: {datetime.datetime.now()}\")\n",
    "# for i in range(len(ML_Models)):\n",
    "#     model = ML_Models[i]\n",
    "#     y_test = []\n",
    "#     y_predict = []\n",
    "#     for test_set in tqdm(test_sets):\n",
    "#         df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#         x_test = scaler.transform(df[X_columns])\n",
    "#         for k in df[Y_columns]:\n",
    "#             y_test.append(ATTACKS_ENUM[dict_7classes[k]].value==ATTACKS[i])\n",
    "#         y_predict+= list(model.predict(x_test))\n",
    "\n",
    "#         del df\n",
    "#         del x_test\n",
    "\n",
    "#     myarr = np.array([ATTACKS_ENUM[dict_7classes[k]].value == ATTACKS_ENUM[ATTACKS[0]].value for k in ['DDoS-RSTFINFlood','DDoS-PSHACK_Flood','DDoS-SYN_Flood','DoS-SYN_Flood','DoS-TCP_Flood','Mirai-udpplain','Recon-OSScan','DNS_Spoofing','BrowserHijacking','Backdoor_Malware','DictionaryBruteForce']])\n",
    "#     print(myarr)\n",
    "#     print(to_categorical(myarr, num_classes=2))\n",
    "#     y_test=np.array(y_test)\n",
    "#     print(y_test[0:10])\n",
    "#     y_test = to_categorical(y_test, num_classes=2)\n",
    "#     print(y_test[0:10])\n",
    "#     print(\"=========\")\n",
    "#     for i in range(10):\n",
    "#         print(f\"{i}: {y_predict[i]} actual {y_test[i]}\")    \n",
    "\n",
    "#     test = np.argmax(y_test, axis=1)\n",
    "#     predict = np.argmax(y_predict, axis=1)\n",
    "#     showResults8Models(test, predict, i)\n",
    "\n",
    "#     del test\n",
    "#     del predict\n",
    "#     del y_test\n",
    "#     del y_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
