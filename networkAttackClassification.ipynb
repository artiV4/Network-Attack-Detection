{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB, BernoulliNB\n",
    "from sklearn.neural_network import BernoulliRBM, MLPClassifier # Unsupervised\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# import tensorflow_decision_forests as tfdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorize and enumerate all attacks in dataset\n",
    "ATTACKS = ['DDoS', 'DoS', 'Mirai', 'Recon', 'Spoofing', 'Benign', 'Web', 'BruteForce']\n",
    "ATTACKS_ENUM = Enum('ATTACKS', ATTACKS, start=0)\n",
    "dict_7classes = {}\n",
    "dict_7classes['DDoS-RSTFINFlood'] = 'DDoS'\n",
    "dict_7classes['DDoS-PSHACK_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SYN_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-TCP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SynonymousIP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ACK_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-SlowLoris'] = 'DDoS'\n",
    "dict_7classes['DDoS-HTTP_Flood'] = 'DDoS'\n",
    "\n",
    "dict_7classes['DoS-UDP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-SYN_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-TCP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-HTTP_Flood'] = 'DoS'\n",
    "\n",
    "\n",
    "dict_7classes['Mirai-greeth_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-greip_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-udpplain'] = 'Mirai'\n",
    "\n",
    "dict_7classes['Recon-PingSweep'] = 'Recon'\n",
    "dict_7classes['Recon-OSScan'] = 'Recon'\n",
    "dict_7classes['Recon-PortScan'] = 'Recon'\n",
    "dict_7classes['VulnerabilityScan'] = 'Recon'\n",
    "dict_7classes['Recon-HostDiscovery'] = 'Recon'\n",
    "\n",
    "dict_7classes['DNS_Spoofing'] = 'Spoofing'\n",
    "dict_7classes['MITM-ArpSpoofing'] = 'Spoofing'\n",
    "\n",
    "dict_7classes['BenignTraffic'] = 'Benign'\n",
    "\n",
    "dict_7classes['BrowserHijacking'] = 'Web'\n",
    "dict_7classes['Backdoor_Malware'] = 'Web'\n",
    "dict_7classes['XSS'] = 'Web'\n",
    "dict_7classes['Uploading_Attack'] = 'Web'\n",
    "dict_7classes['SqlInjection'] = 'Web'\n",
    "dict_7classes['CommandInjection'] = 'Web'\n",
    "\n",
    "\n",
    "dict_7classes['DictionaryBruteForce'] = 'BruteForce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Generation of CSV data =====\n",
    "# Adapted from same source as Dataset\n",
    "#import pcap2csv\n",
    "run_this = False\n",
    "if(run_this):\n",
    "    from pcap2csv import Generating_dataset #Generating_dataset#, Supporting_functions, Communication_features, Connectivity_features, Dynamic_features, Feature_extraction, Layered_features\n",
    "    import os\n",
    "    PCAP_DIRECTORY = 'pcap/'\n",
    "    pcap_files = [k for k in os.listdir(PCAP_DIRECTORY) if k.endswith('.pcap')] \n",
    "    Generating_dataset.make_csv(pcap_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====Split Train / Test data======\n",
    "# Dataset link-> https://www.unb.ca/cic/datasets/iotdataset-2023.html\n",
    "#E. C. P. Neto, S. Dadkhah, R. Ferreira, A. Zohourian, R. Lu, A. A. Ghorbani. \"CICIoT2023: A real-time dataset and benchmark for large-scale attacks in IoT environment,\" Sensor (2023) – (submitted to Journal of Sensors).\n",
    "\n",
    "DATASET_DIRECTORY = 'dataset/'\n",
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')] # all files\n",
    "#df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('1-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')] # smaller subset for faster testing, 17 files =  10% of whole dataset\n",
    "#df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('11-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')] # 2 files = 1%\n",
    "df_sets.sort()\n",
    "training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "test_sets = df_sets[int(len(df_sets)*.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Extract Data=====\n",
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "       'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "       'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "       'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "       'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "       'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "       'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "] #columns 0-45\n",
    "Y_columns = 'label' #column 46\n",
    "\n",
    "all_columns = X_columns+[Y_columns]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "      'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "      'Rate', 'Srate', 'Drate', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "      'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "      'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "]\n",
    "CATEGORICAL_FEATURE_NAMES = [\n",
    "      'fin_flag_number', 'syn_flag_number',\n",
    "      'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "      'ece_flag_number', 'cwr_flag_number','HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "      'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "#=====Feature Scaling======\n",
    "# columnsToScale = ['flow_duration', 'Header_Length', 'Duration', 'Rate', 'Srate', 'Drate', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'fin_count']\n",
    "# scale all\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "for train_set in tqdm(training_sets):\n",
    "    df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[X_columns]\n",
    "    x_train = scaler.fit(df)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, model, name, type):\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.type = type\n",
    "        #self.batch_size = batch_size\n",
    "\n",
    "TYPES = {}\n",
    "TYPES['SK_LR'] = 1\n",
    "TYPES['SK_RF'] = 2\n",
    "TYPES['TF'] = 3\n",
    "\n",
    "verbose, epochs, batch_size = 0, 10, 512\n",
    "activationFunction='relu'\n",
    "\n",
    "# def getOtimizedSequentialModel():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(46, activation=activationFunction))\n",
    "#     model.add(Dense(30, activation=activationFunction))\n",
    "#     model.add(Dense(8, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return model\n",
    "\n",
    "def getANN():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(46, activation=activationFunction))\n",
    "    model.add(Dense(30, activation=activationFunction))\n",
    "    model.add(Dense(20, activation=activationFunction))\n",
    "    model.add(Dense(12, activation=activationFunction))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                    metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "                    )\n",
    "    return Model(model, \"ANN\", TYPES['TF'])\n",
    "\n",
    "\n",
    "def getCNN1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 46, activation=activationFunction))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(64, 46, activation=activationFunction))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(64, 46, activation=activationFunction))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=activationFunction))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    return Model(model, 'CNN', TYPES['TF'])\n",
    "\n",
    "def getRFModel():\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        criterion = 'gini',\n",
    "        max_depth=None,\n",
    "        )\n",
    "    return Model(rf, \"RF\", TYPES['SK_RF'])\n",
    "\n",
    "def getLRModel():\n",
    "    lr = LogisticRegression()\n",
    "    return Model(lr, \"LR\", TYPES['SK_LR'])\n",
    "\n",
    "def getSVCModel():\n",
    "    model = SVC()\n",
    "    return Model(model, \"Lin-SVC\", TYPES['SK_LR'])\n",
    "\n",
    "def getLinSVCModel():\n",
    "    model = LinearSVC(tol = 1e-5)\n",
    "    return Model(model, \"Lin-SVC\", TYPES['SK_LR'])\n",
    "\n",
    "def getSGDCModel():\n",
    "    model = SGDClassifier(loss='hinge')\n",
    "    return Model(model, \"SGDC Hinge\", TYPES['SK_LR'])\n",
    "\n",
    "def getSGDC_LogLossModel():\n",
    "    model = SGDClassifier(loss='log_loss')\n",
    "    return Model(model, \"SGDC LogLoss\", TYPES['SK_LR'])\n",
    "\n",
    "def getSGDC_HuberModel():\n",
    "    model = SGDClassifier(loss='modified_huber')\n",
    "    return Model(model, \"SGDC Modified Huber\", TYPES['SK_LR'])\n",
    "\n",
    "def getKNNCModel():\n",
    "    model = KNeighborsClassifier()\n",
    "    return Model(model, \"KNNC\", TYPES['SK_LR'])\n",
    "\n",
    "def getRadNNCModel():\n",
    "    model = RadiusNeighborsClassifier()\n",
    "    return Model(model, \"RadNNC\", TYPES['SK_LR'])\n",
    "\n",
    "def getNCentModel():\n",
    "    model = NearestCentroid()\n",
    "    return Model(model, \"NCent\", TYPES['SK_LR'])\n",
    "\n",
    "def getRidgeModel():\n",
    "    model = RidgeClassifier(solver='saga')\n",
    "    return Model(model, \"Ridge\", TYPES['SK_RF'])\n",
    "\n",
    "# === Test bottom models later ===\n",
    "\n",
    "def getBRBMModel():\n",
    "    model = BernoulliRBM()\n",
    "    return Model(model, \"Bernoulli Restricted Bolzman Machine\", TYPES['SK_RF'])\n",
    "\n",
    "def getBNBModel():\n",
    "    model = BernoulliNB()\n",
    "    return Model(model, \"Bernoulli Naive Bayes\", TYPES['SK_RF'])\n",
    "\n",
    "def getCNBModel():\n",
    "    model = CategoricalNB()\n",
    "    return Model(model, \"Categocical Naive Bayes\", TYPES['SK_RF'])\n",
    "\n",
    "def getGNBModel():\n",
    "    model = GaussianNB()\n",
    "    return Model(model, \"Gausian Naive Bayes\", TYPES['SK_RF'])\n",
    "\n",
    "def getMLPCModel():\n",
    "    model = MLPClassifier() #MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)  \n",
    "    return Model(model, \"Bernoulli\", TYPES['SK_RF'])\n",
    "\n",
    "def getNUSVCModel():\n",
    "    model = NuSVC()\n",
    "    return Model(model, \"NuSVC\", TYPES['SK_LR'])\n",
    "\n",
    "ML_Models = [\n",
    "            # getSVCModel(), # bad - infinite training\n",
    "            getLinSVCModel(), # good\n",
    "            getSGDCModel(), #good\n",
    "            getSGDC_LogLossModel(),\n",
    "            getSGDC_HuberModel(),\n",
    "            getKNNCModel(), #good results - long prediction time\n",
    "            # getRadNNCModel(), #bad - infinite testing?\n",
    "            getNCentModel(), # good\n",
    "            getRidgeModel(), # good\n",
    "            # getBRBMModel(),\n",
    "            # getBNBModel(),\n",
    "            # getCNBModel(),\n",
    "            # getGNBModel(),\n",
    "            #getGNBModel(), # good\n",
    "            # getNUSVCModel(), # bad - error\n",
    "            # getMLPCModel(), # unsupervised\n",
    "            # getNUSVCModel() # unsupervised\n",
    "\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ran on 8 models, with 1 training sets on date: 2024-06-15 01:06:24.801329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:03<00:00, 123.87s/it]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Last ran on {len(ML_Models)} models, with {len(training_sets)} training sets on date: {datetime.datetime.now()}\")\n",
    "for train_set in tqdm(training_sets):\n",
    "    df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "    x_train = scaler.transform(df[X_columns])\n",
    "    y_train = [ATTACKS_ENUM[dict_7classes[k]].value for k in df[Y_columns]]\n",
    "    y_train_Cat = to_categorical(y_train, num_classes=8)\n",
    "\n",
    "    for i in range(len(ML_Models)):\n",
    "            model = ML_Models[i]\n",
    "            if model.type==TYPES[\"SK_LR\"]:\n",
    "                model.model.fit(x_train, y_train)  \n",
    "            \n",
    "            elif model.type==TYPES[\"SK_RF\"]:\n",
    "                model.model.fit(x_train, y_train_Cat)  \n",
    "\n",
    "            elif model.type == TYPES[\"TF\"]:\n",
    "                model.model.fit(x=x_train, \n",
    "                            y=y_train_Cat, \n",
    "                            epochs=epochs, \n",
    "                            verbose=verbose,\n",
    "                            batch_size=batch_size)                   \n",
    "    del df\n",
    "    del x_train\n",
    "    del y_train\n",
    "    del y_train_Cat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the resulting trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResults(test, pred,model_name):\n",
    "    output = ''\n",
    "    output += str(datetime.datetime.now())\n",
    "    output += f\"\\n===== {model_name} =====\\n\"\n",
    "    output+=classification_report(test, pred, target_names=ATTACKS)\n",
    "    accuracy = accuracy_score(test, pred)\n",
    "    precision=precision_score(test, pred, average='weighted')\n",
    "    f1Score=f1_score(test, pred, average='weighted') \n",
    "    output+=f\"\\nAccuracy  : {accuracy}\\n\"\n",
    "    output+=f\"Precision : {precision}\\n\"\n",
    "    output+=f\"f1Score : {f1Score}\\n\"\n",
    "    cm=confusion_matrix(test, pred)\n",
    "    output+=str(cm) \n",
    "    \n",
    "    joblib.dump(output, f\"outputs/{model_name}.txt\") \n",
    "\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model):\n",
    "    y_test = []\n",
    "    y_predict = []\n",
    "    for test_set in tqdm(test_sets):\n",
    "        df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "        x_test = scaler.transform(df[X_columns])\n",
    "        for k in df[Y_columns]:\n",
    "            y_test.append(ATTACKS_ENUM[dict_7classes[k]].value)\n",
    "        if model.type == TYPES['TF']:\n",
    "            y_predict+= list(model.model.predict(x_test, verbose=0))\n",
    "        elif model.type == TYPES['SK_LR'] or model.type == TYPES[\"SK_RF\"]:\n",
    "            y_predict+= list(model.model.predict(x_test))\n",
    "\n",
    "        del df\n",
    "        del x_test\n",
    "\n",
    "    y_test=np.array(y_test)\n",
    "    if model.type == TYPES['TF'] or model.type ==TYPES[\"SK_RF\"]:\n",
    "        y_test = to_categorical(y_test, num_classes=8)\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "        y_predict = np.argmax(y_predict, axis=1)\n",
    "    showResults(y_test, y_predict, model.name)\n",
    "\n",
    "\n",
    "    del y_test\n",
    "    del y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ML_Models)):\n",
    "    model = ML_Models[i]\n",
    "    if model.type==TYPES[\"TF\"]:\n",
    "        model.model.save(f\"SavedModels\\\\{model.name}.keras\",overwrite=True)\n",
    "    elif model.type==TYPES[\"SK_RF\"] or model.type==TYPES[\"SK_LR\"]:\n",
    "        joblib.dump(model.model, f\"SavedModels/{model.name}.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ran on 8 models, with 1 testing sets on date: 2024-06-15 01:08:28.724636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-15 01:08:29.785715\n",
      "===== Lin-SVC =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.82      0.99      0.90    196031\n",
      "         DoS       0.74      0.10      0.18     46701\n",
      "       Mirai       0.98      0.99      0.99     15235\n",
      "       Recon       0.64      0.25      0.36      2034\n",
      "    Spoofing       0.79      0.26      0.39      2796\n",
      "      Benign       0.67      0.86      0.76      6240\n",
      "         Web       0.00      0.00      0.00       143\n",
      "  BruteForce       1.00      0.12      0.22        73\n",
      "\n",
      "    accuracy                           0.82    269253\n",
      "   macro avg       0.71      0.45      0.47    269253\n",
      "weighted avg       0.81      0.82      0.77    269253\n",
      "\n",
      "Accuracy  : 0.8217958574277724\n",
      "Precision : 0.8095918215356802\n",
      "f1Score : 0.7653423871357131\n",
      "[[194756    910      3     37     21    304      0      0]\n",
      " [ 41690   4803     16     25     20    145      2      0]\n",
      " [    22     41  15094      2     15     61      0      0]\n",
      " [   429    235     10    508     33    819      0      0]\n",
      " [   455    236    156     56    727   1166      0      0]\n",
      " [   354    225     38    147    101   5374      1      0]\n",
      " [    26     23      7     10      3     74      0      0]\n",
      " [    12      9      1      4      2     36      0      9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-15 01:08:31.380678\n",
      "===== SGDC Hinge =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.80      1.00      0.89    196031\n",
      "         DoS       0.64      0.00      0.00     46701\n",
      "       Mirai       0.98      0.99      0.98     15235\n",
      "       Recon       0.79      0.12      0.21      2034\n",
      "    Spoofing       0.61      0.12      0.19      2796\n",
      "      Benign       0.60      0.82      0.69      6240\n",
      "         Web       0.06      0.01      0.02       143\n",
      "  BruteForce       1.00      0.07      0.13        73\n",
      "\n",
      "    accuracy                           0.80    269253\n",
      "   macro avg       0.68      0.39      0.39    269253\n",
      "weighted avg       0.77      0.80      0.72    269253\n",
      "\n",
      "Accuracy  : 0.8027134330908104\n",
      "Precision : 0.7744334760171304\n",
      "f1Score : 0.7215576739157472\n",
      "[[195304     10    139     13      7    553      5      0]\n",
      " [ 46298     51      9     16     12    304     11      0]\n",
      " [    93      4  15058      0     11     65      4      0]\n",
      " [   830      8      1    242     43    909      1      0]\n",
      " [   767      4    177     13    324   1506      5      0]\n",
      " [   918      2     16     16    133   5147      8      0]\n",
      " [    53      1      4      4      1     78      2      0]\n",
      " [    27      0      0      1      1     39      0      5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-15 01:08:32.996963\n",
      "===== SGDC LogLoss =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.80      0.99      0.89    196031\n",
      "         DoS       0.16      0.01      0.01     46701\n",
      "       Mirai       0.99      0.99      0.99     15235\n",
      "       Recon       0.74      0.12      0.20      2034\n",
      "    Spoofing       0.63      0.18      0.28      2796\n",
      "      Benign       0.61      0.81      0.70      6240\n",
      "         Web       0.00      0.00      0.00       143\n",
      "  BruteForce       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.80    269253\n",
      "   macro avg       0.49      0.39      0.38    269253\n",
      "weighted avg       0.69      0.80      0.73    269253\n",
      "\n",
      "Accuracy  : 0.8025017362852038\n",
      "Precision : 0.6948977448321642\n",
      "f1Score : 0.7251007980678462\n",
      "[[194960    307      3      9    216    536      0      0]\n",
      " [ 46119    277      6      8     15    276      0      0]\n",
      " [    51     78  15040      0      4     62      0      0]\n",
      " [   599    334      2    236      9    854      0      0]\n",
      " [   514    263    154     10    501   1354      0      0]\n",
      " [   648    387     40     51     52   5062      0      0]\n",
      " [    44     23      5      3      3     65      0      0]\n",
      " [    21     13      0      3      0     36      0      0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-15 01:08:34.578131\n",
      "===== SGDC Modified Huber =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.81      0.99      0.90    196031\n",
      "         DoS       0.67      0.08      0.14     46701\n",
      "       Mirai       0.98      0.99      0.99     15235\n",
      "       Recon       0.61      0.25      0.35      2034\n",
      "    Spoofing       0.88      0.17      0.29      2796\n",
      "      Benign       0.62      0.84      0.71      6240\n",
      "         Web       0.00      0.00      0.00       143\n",
      "  BruteForce       1.00      0.12      0.22        73\n",
      "\n",
      "    accuracy                           0.81    269253\n",
      "   macro avg       0.70      0.43      0.45    269253\n",
      "weighted avg       0.79      0.81      0.75    269253\n",
      "\n",
      "Accuracy  : 0.8149955617950404\n",
      "Precision : 0.7933893435948004\n",
      "f1Score : 0.7535251287765302\n",
      "[[194566    792     54     46     15    558      0      0]\n",
      " [ 42768   3579      6     40     12    296      0      0]\n",
      " [    28     64  15061      1      4     77      0      0]\n",
      " [   459    241      0    507     10    817      0      0]\n",
      " [   402    322    174     49    489   1360      0      0]\n",
      " [   479    321     17    173     21   5229      0      0]\n",
      " [    33     22      5     11      1     71      0      0]\n",
      " [    15     10      0      2      1     36      0      9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:58<00:00, 58.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-15 01:09:33.177604\n",
      "===== KNNC =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.97      0.98      0.97    196031\n",
      "         DoS       0.91      0.86      0.88     46701\n",
      "       Mirai       1.00      0.99      1.00     15235\n",
      "       Recon       0.60      0.57      0.58      2034\n",
      "    Spoofing       0.67      0.56      0.61      2796\n",
      "      Benign       0.75      0.85      0.80      6240\n",
      "         Web       0.27      0.04      0.07       143\n",
      "  BruteForce       0.82      0.12      0.21        73\n",
      "\n",
      "    accuracy                           0.95    269253\n",
      "   macro avg       0.75      0.62      0.64    269253\n",
      "weighted avg       0.95      0.95      0.95    269253\n",
      "\n",
      "Accuracy  : 0.9470015190174297\n",
      "Precision : 0.9460477403153176\n",
      "f1Score : 0.9461392532924253\n",
      "[[191841   4114     19     51      6      0      0      0]\n",
      " [  6659  39997     12     31      2      0      0      0]\n",
      " [    79     21  15122      9      4      0      0      0]\n",
      " [    48     18      7   1161    184    611      4      1]\n",
      " [     5      2      0    222   1557   1000      9      1]\n",
      " [     3      5      0    415    524   5290      3      0]\n",
      " [     1      0      0     28     33     75      6      0]\n",
      " [     0      0      0     19     12     33      0      9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "print(f\"Last ran on {len(ML_Models)} models, with {len(test_sets)} testing sets on date: {datetime.datetime.now()}\")\n",
    "for i in range(len(ML_Models)):\n",
    "    testModel(ML_Models[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n",
      "done\n",
      "2024-06-15 00:21:12.827986\n",
      "===== TEst =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.97      0.98      0.97    196031\n",
      "         DoS       0.91      0.86      0.88     46701\n",
      "       Mirai       1.00      0.99      1.00     15235\n",
      "       Recon       0.60      0.57      0.58      2034\n",
      "    Spoofing       0.67      0.56      0.61      2796\n",
      "      Benign       0.75      0.85      0.80      6240\n",
      "         Web       0.27      0.04      0.07       143\n",
      "  BruteForce       0.82      0.12      0.21        73\n",
      "\n",
      "    accuracy                           0.95    269253\n",
      "   macro avg       0.75      0.62      0.64    269253\n",
      "weighted avg       0.95      0.95      0.95    269253\n",
      "\n",
      "Accuracy  : 0.9470015190174297\n",
      "Precision : 0.9460477403153176\n",
      "f1Score : 0.9461392532924253\n",
      "[[191841   4114     19     51      6      0      0      0]\n",
      " [  6659  39997     12     31      2      0      0      0]\n",
      " [    79     21  15122      9      4      0      0      0]\n",
      " [    48     18      7   1161    184    611      4      1]\n",
      " [     5      2      0    222   1557   1000      9      1]\n",
      " [     3      5      0    415    524   5290      3      0]\n",
      " [     1      0      0     28     33     75      6      0]\n",
      " [     0      0      0     19     12     33      0      9]]\n"
     ]
    }
   ],
   "source": [
    "# model = ML_Models[i].model\n",
    "# for test_set in test_sets:\n",
    "#     df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#     x_test = scaler.transform(df[X_columns])\n",
    "#     y_test = [ATTACKS_ENUM[dict_7classes[k]].value for k in df[Y_columns]]\n",
    "#     print(\"predicting\")\n",
    "#     y_predict = model.predict(x_test)\n",
    "#     print(\"done\")\n",
    "#     y_test=np.array(y_test)\n",
    "\n",
    "#     showResults(y_test, y_predict, \"TEst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====For debug ===\n",
    "# test_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')] \n",
    "#testModel(load_model(\"SavedModels\\\\BestANN.keras\"), \"Best ANN so far\")\n",
    "#testModel(Model(joblib.load(\"SavedModels/BestRF.pkl\"),\"debug_DF\", TYPES['SK_RF']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(ML_Models)):\n",
    "#     model = ML_Models[i]\n",
    "#     if model.type==TYPES[\"TF\"]:\n",
    "#         model.model.save(f\"SavedModels\\\\{model.name}.keras\",overwrite=True)\n",
    "#     elif model.type==TYPES[\"SK_RF\"] or model.type==TYPES[\"SK_LR\"]:\n",
    "#         joblib.dump(model.model, f\"SavedModels/{model.name}.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a seperate model to detect each attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose, epochs, batch_size = 1, 100, 512\n",
    "# activationFunction='relu'\n",
    "\n",
    "# def getSequentialModel():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(128, activation=activationFunction))\n",
    "#     model.add(Dense(64, activation=activationFunction))\n",
    "#     model.add(Dense(32, activation=activationFunction))\n",
    "#     model.add(Dense(16, activation=activationFunction))\n",
    "#     model.add(Dense(8, activation=activationFunction))\n",
    "#     model.add(Dense(4, activation=activationFunction))\n",
    "#     model.add(Dense(2, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return model\n",
    "\n",
    "# ML_Models = [\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel()\n",
    "\n",
    "# ]\n",
    "# ML_Model_Names = ATTACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Last ran on {len(ML_Models)} models, with {len(training_sets)} training sets on date: {datetime.datetime.now()}\")\n",
    "# for train_set in tqdm(training_sets):\n",
    "#     df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#     x_train = scaler.transform(df[X_columns])\n",
    "\n",
    "#     for i in range(len(ML_Models)-1):\n",
    "#             y_train = to_categorical([ATTACKS_ENUM[dict_7classes[k]].value == ATTACKS_ENUM[ATTACKS[i]].value for k in df[Y_columns]], num_classes=2)\n",
    "#             model = ML_Models[i]\n",
    "#             model.fit(x=x_train, \n",
    "#                         y=y_train, \n",
    "#                         epochs=epochs, \n",
    "#                         verbose=verbose,\n",
    "#                         batch_size=batch_size)   \n",
    "#             del y_train             \n",
    "#     del df\n",
    "#     del x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def showResults8Models(test, pred, model_num):\n",
    "#     print(f\"===== {model_num} =====\")\n",
    "#     print(classification_report(test, pred, target_names=[\"Negative\", \"Positive\"]))\n",
    "#     accuracy = accuracy_score(test, pred)\n",
    "#     precision=precision_score(test, pred, average='weighted')\n",
    "#     f1Score=f1_score(test, pred, average='weighted') \n",
    "#     print(\"Accuracy  : {}\".format(accuracy))\n",
    "#     print(\"Precision : {}\".format(precision))\n",
    "#     print(\"f1Score : {}\".format(f1Score))\n",
    "#     cm=confusion_matrix(test, pred)\n",
    "#     print(cm) \n",
    "\n",
    "# print(f\"Last ran on {len(ML_Models)} models, with {len(test_sets)} testing sets on date: {datetime.datetime.now()}\")\n",
    "# for i in range(len(ML_Models)):\n",
    "#     model = ML_Models[i]\n",
    "#     y_test = []\n",
    "#     y_predict = []\n",
    "#     for test_set in tqdm(test_sets):\n",
    "#         df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#         x_test = scaler.transform(df[X_columns])\n",
    "#         for k in df[Y_columns]:\n",
    "#             y_test.append(ATTACKS_ENUM[dict_7classes[k]].value==ATTACKS[i])\n",
    "#         y_predict+= list(model.predict(x_test))\n",
    "\n",
    "#         del df\n",
    "#         del x_test\n",
    "\n",
    "#     myarr = np.array([ATTACKS_ENUM[dict_7classes[k]].value == ATTACKS_ENUM[ATTACKS[0]].value for k in ['DDoS-RSTFINFlood','DDoS-PSHACK_Flood','DDoS-SYN_Flood','DoS-SYN_Flood','DoS-TCP_Flood','Mirai-udpplain','Recon-OSScan','DNS_Spoofing','BrowserHijacking','Backdoor_Malware','DictionaryBruteForce']])\n",
    "#     print(myarr)\n",
    "#     print(to_categorical(myarr, num_classes=2))\n",
    "#     y_test=np.array(y_test)\n",
    "#     print(y_test[0:10])\n",
    "#     y_test = to_categorical(y_test, num_classes=2)\n",
    "#     print(y_test[0:10])\n",
    "#     print(\"=========\")\n",
    "#     for i in range(10):\n",
    "#         print(f\"{i}: {y_predict[i]} actual {y_test[i]}\")    \n",
    "\n",
    "#     test = np.argmax(y_test, axis=1)\n",
    "#     predict = np.argmax(y_predict, axis=1)\n",
    "#     showResults8Models(test, predict, i)\n",
    "\n",
    "#     del test\n",
    "#     del predict\n",
    "#     del y_test\n",
    "#     del y_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
