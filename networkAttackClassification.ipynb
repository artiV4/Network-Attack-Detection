{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# import tensorflow_decision_forests as tfdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorize and enumerate all attacks in dataset\n",
    "ATTACKS = ['DDoS', 'DoS', 'Mirai', 'Recon', 'Spoofing', 'Benign', 'Web', 'BruteForce']\n",
    "ATTACKS_ENUM = Enum('ATTACKS', ATTACKS, start=0)\n",
    "dict_7classes = {}\n",
    "dict_7classes['DDoS-RSTFINFlood'] = 'DDoS'\n",
    "dict_7classes['DDoS-PSHACK_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SYN_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-TCP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SynonymousIP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ACK_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-SlowLoris'] = 'DDoS'\n",
    "dict_7classes['DDoS-HTTP_Flood'] = 'DDoS'\n",
    "\n",
    "dict_7classes['DoS-UDP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-SYN_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-TCP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-HTTP_Flood'] = 'DoS'\n",
    "\n",
    "\n",
    "dict_7classes['Mirai-greeth_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-greip_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-udpplain'] = 'Mirai'\n",
    "\n",
    "dict_7classes['Recon-PingSweep'] = 'Recon'\n",
    "dict_7classes['Recon-OSScan'] = 'Recon'\n",
    "dict_7classes['Recon-PortScan'] = 'Recon'\n",
    "dict_7classes['VulnerabilityScan'] = 'Recon'\n",
    "dict_7classes['Recon-HostDiscovery'] = 'Recon'\n",
    "\n",
    "dict_7classes['DNS_Spoofing'] = 'Spoofing'\n",
    "dict_7classes['MITM-ArpSpoofing'] = 'Spoofing'\n",
    "\n",
    "dict_7classes['BenignTraffic'] = 'Benign'\n",
    "\n",
    "dict_7classes['BrowserHijacking'] = 'Web'\n",
    "dict_7classes['Backdoor_Malware'] = 'Web'\n",
    "dict_7classes['XSS'] = 'Web'\n",
    "dict_7classes['Uploading_Attack'] = 'Web'\n",
    "dict_7classes['SqlInjection'] = 'Web'\n",
    "dict_7classes['CommandInjection'] = 'Web'\n",
    "\n",
    "\n",
    "dict_7classes['DictionaryBruteForce'] = 'BruteForce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====Split Train / Test data======\n",
    "# Dataset link-> https://www.unb.ca/cic/datasets/iotdataset-2023.html\n",
    "#E. C. P. Neto, S. Dadkhah, R. Ferreira, A. Zohourian, R. Lu, A. A. Ghorbani. \"CICIoT2023: A real-time dataset and benchmark for large-scale attacks in IoT environment,\" Sensor (2023) – (submitted to Journal of Sensors).\n",
    "\n",
    "DATASET_DIRECTORY = 'dataset/'\n",
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')] # all files\n",
    "#df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('1-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')] # smaller subset for faster testing, 17 files =  10% of whole dataset\n",
    "#df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('11-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')] # 2 files = 1%\n",
    "df_sets.sort()\n",
    "training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "test_sets = df_sets[int(len(df_sets)*.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Extract Data=====\n",
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "       'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "       'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "       'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "       'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "       'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "       'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "] #columns 0-45\n",
    "Y_columns = 'label' #column 46\n",
    "\n",
    "all_columns = X_columns+[Y_columns]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "      'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "      'Rate', 'Srate', 'Drate', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "      'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "      'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "]\n",
    "CATEGORICAL_FEATURE_NAMES = [\n",
    "      'fin_flag_number', 'syn_flag_number',\n",
    "      'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "      'ece_flag_number', 'cwr_flag_number','HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "      'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [03:02<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "#=====Feature Scaling======\n",
    "# columnsToScale = ['flow_duration', 'Header_Length', 'Duration', 'Rate', 'Srate', 'Drate', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'fin_count']\n",
    "# scale all\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "for train_set in tqdm(training_sets):\n",
    "    df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[X_columns]\n",
    "    x_train = scaler.fit(df)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, model, name, type):\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.type = type\n",
    "        #self.batch_size = batch_size\n",
    "\n",
    "TYPES = {}\n",
    "TYPES['SK_LR'] = 1\n",
    "TYPES['SK_RF'] = 2\n",
    "TYPES['TF'] = 3\n",
    "\n",
    "verbose, epochs, batch_size = 0, 10, 512\n",
    "activationFunction='relu'\n",
    "\n",
    "# def getOtimizedSequentialModel():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(46, activation=activationFunction))\n",
    "#     model.add(Dense(30, activation=activationFunction))\n",
    "#     model.add(Dense(8, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return model\n",
    "\n",
    "def getANN():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(46, activation=activationFunction))\n",
    "    model.add(Dense(30, activation=activationFunction))\n",
    "    model.add(Dense(20, activation=activationFunction))\n",
    "    model.add(Dense(12, activation=activationFunction))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                    metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "                    )\n",
    "    return Model(model, \"ANN\", TYPES['TF'])\n",
    "\n",
    "\n",
    "def getCNN1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 46, activation=activationFunction))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(64, 46, activation=activationFunction))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(64, 46, activation=activationFunction))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=activationFunction))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    return Model(model, 'CNN', TYPES['TF'])\n",
    "\n",
    "def getRFModel():\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        criterion = 'gini',\n",
    "        max_depth=None,\n",
    "        )\n",
    "    return Model(rf, \"RF\", TYPES['SK_RF'])\n",
    "\n",
    "def getLRModel():\n",
    "    lr = LogisticRegression()\n",
    "    return Model(lr, \"LR\", TYPES['SK_LR'])\n",
    "\n",
    "\n",
    "\n",
    "ML_Models = [\n",
    "            getANN(),\n",
    "            getRFModel(),\n",
    "            getLRModel()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ran on 3 models, with 135 training sets on date: 2024-06-04 19:51:36.545307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [3:06:34<00:00, 82.93s/it]  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Last ran on {len(ML_Models)} models, with {len(training_sets)} training sets on date: {datetime.datetime.now()}\")\n",
    "for train_set in tqdm(training_sets):\n",
    "    df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "    x_train = scaler.transform(df[X_columns])\n",
    "    y_train = [ATTACKS_ENUM[dict_7classes[k]].value for k in df[Y_columns]]\n",
    "    y_train_Cat = to_categorical(y_train, num_classes=8)\n",
    "\n",
    "    for i in range(len(ML_Models)):\n",
    "            model = ML_Models[i]\n",
    "            if model.type==TYPES[\"SK_LR\"]:\n",
    "                model.model.fit(x_train, y_train)  \n",
    "            \n",
    "            elif model.type==TYPES[\"SK_RF\"]:\n",
    "                model.model.fit(x_train, y_train_Cat)  \n",
    "\n",
    "            elif model.type == TYPES[\"TF\"]:\n",
    "                model.model.fit(x=x_train, \n",
    "                            y=y_train_Cat, \n",
    "                            epochs=epochs, \n",
    "                            verbose=verbose,\n",
    "                            batch_size=batch_size)                   \n",
    "    del df\n",
    "    del x_train\n",
    "    del y_train\n",
    "    del y_train_Cat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a seperate model to detect each attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose, epochs, batch_size = 1, 100, 512\n",
    "# activationFunction='relu'\n",
    "\n",
    "# def getSequentialModel():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(128, activation=activationFunction))\n",
    "#     model.add(Dense(64, activation=activationFunction))\n",
    "#     model.add(Dense(32, activation=activationFunction))\n",
    "#     model.add(Dense(16, activation=activationFunction))\n",
    "#     model.add(Dense(8, activation=activationFunction))\n",
    "#     model.add(Dense(4, activation=activationFunction))\n",
    "#     model.add(Dense(2, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return model\n",
    "\n",
    "# ML_Models = [\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel()\n",
    "\n",
    "# ]\n",
    "# ML_Model_Names = ATTACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Last ran on {len(ML_Models)} models, with {len(training_sets)} training sets on date: {datetime.datetime.now()}\")\n",
    "# for train_set in tqdm(training_sets):\n",
    "#     df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#     x_train = scaler.transform(df[X_columns])\n",
    "\n",
    "#     for i in range(len(ML_Models)-1):\n",
    "#             y_train = to_categorical([ATTACKS_ENUM[dict_7classes[k]].value == ATTACKS_ENUM[ATTACKS[i]].value for k in df[Y_columns]], num_classes=2)\n",
    "#             model = ML_Models[i]\n",
    "#             model.fit(x=x_train, \n",
    "#                         y=y_train, \n",
    "#                         epochs=epochs, \n",
    "#                         verbose=verbose,\n",
    "#                         batch_size=batch_size)   \n",
    "#             del y_train             \n",
    "#     del df\n",
    "#     del x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def showResults8Models(test, pred, model_num):\n",
    "#     print(f\"===== {model_num} =====\")\n",
    "#     print(classification_report(test, pred, target_names=[\"Negative\", \"Positive\"]))\n",
    "#     accuracy = accuracy_score(test, pred)\n",
    "#     precision=precision_score(test, pred, average='weighted')\n",
    "#     f1Score=f1_score(test, pred, average='weighted') \n",
    "#     print(\"Accuracy  : {}\".format(accuracy))\n",
    "#     print(\"Precision : {}\".format(precision))\n",
    "#     print(\"f1Score : {}\".format(f1Score))\n",
    "#     cm=confusion_matrix(test, pred)\n",
    "#     print(cm) \n",
    "\n",
    "# print(f\"Last ran on {len(ML_Models)} models, with {len(test_sets)} testing sets on date: {datetime.datetime.now()}\")\n",
    "# for i in range(len(ML_Models)):\n",
    "#     model = ML_Models[i]\n",
    "#     y_test = []\n",
    "#     y_predict = []\n",
    "#     for test_set in tqdm(test_sets):\n",
    "#         df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#         x_test = scaler.transform(df[X_columns])\n",
    "#         for k in df[Y_columns]:\n",
    "#             y_test.append(ATTACKS_ENUM[dict_7classes[k]].value==ATTACKS[i])\n",
    "#         y_predict+= list(model.predict(x_test))\n",
    "\n",
    "#         del df\n",
    "#         del x_test\n",
    "\n",
    "#     myarr = np.array([ATTACKS_ENUM[dict_7classes[k]].value == ATTACKS_ENUM[ATTACKS[0]].value for k in ['DDoS-RSTFINFlood','DDoS-PSHACK_Flood','DDoS-SYN_Flood','DoS-SYN_Flood','DoS-TCP_Flood','Mirai-udpplain','Recon-OSScan','DNS_Spoofing','BrowserHijacking','Backdoor_Malware','DictionaryBruteForce']])\n",
    "#     print(myarr)\n",
    "#     print(to_categorical(myarr, num_classes=2))\n",
    "#     y_test=np.array(y_test)\n",
    "#     print(y_test[0:10])\n",
    "#     y_test = to_categorical(y_test, num_classes=2)\n",
    "#     print(y_test[0:10])\n",
    "#     print(\"=========\")\n",
    "#     for i in range(10):\n",
    "#         print(f\"{i}: {y_predict[i]} actual {y_test[i]}\")    \n",
    "\n",
    "#     test = np.argmax(y_test, axis=1)\n",
    "#     predict = np.argmax(y_predict, axis=1)\n",
    "#     showResults8Models(test, predict, i)\n",
    "\n",
    "#     del test\n",
    "#     del predict\n",
    "#     del y_test\n",
    "#     del y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the resulting trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResults(test, pred,model_name):\n",
    "    output = ''\n",
    "    output += str(datetime.datetime.now())\n",
    "    output += f\"\\n===== {model_name} =====\\n\"\n",
    "    output+=classification_report(test, pred, target_names=ATTACKS)\n",
    "    accuracy = accuracy_score(test, pred)\n",
    "    precision=precision_score(test, pred, average='weighted')\n",
    "    f1Score=f1_score(test, pred, average='weighted') \n",
    "    output+=f\"\\nAccuracy  : {accuracy}\\n\"\n",
    "    output+=f\"Precision : {precision}\\n\"\n",
    "    output+=f\"f1Score : {f1Score}\\n\"\n",
    "    cm=confusion_matrix(test, pred)\n",
    "    output+=str(cm) \n",
    "    \n",
    "    joblib.dump(output, f\"outputs/{model_name}.txt\") \n",
    "\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model):\n",
    "    y_test = []\n",
    "    y_predict = []\n",
    "    for test_set in tqdm(test_sets):\n",
    "        df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "        x_test = scaler.transform(df[X_columns])\n",
    "        for k in df[Y_columns]:\n",
    "            y_test.append(ATTACKS_ENUM[dict_7classes[k]].value)\n",
    "        if model.type == TYPES['TF']:\n",
    "            y_predict+= list(model.model.predict(x_test, verbose=0))\n",
    "        elif model.type == TYPES['SK_LR'] or model.type == TYPES[\"SK_RF\"]:\n",
    "            y_predict+= list(model.model.predict(x_test))\n",
    "\n",
    "        del df\n",
    "        del x_test\n",
    "\n",
    "    y_test=np.array(y_test)\n",
    "    if model.type == TYPES['TF'] or model.type ==TYPES[\"SK_RF\"]:\n",
    "        y_test = to_categorical(y_test, num_classes=8)\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "        y_predict = np.argmax(y_predict, axis=1)\n",
    "    showResults(y_test, y_predict, model.name)\n",
    "\n",
    "\n",
    "    del y_test\n",
    "    del y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ran on 3 models, with 34 testing sets on date: 2024-06-04 22:58:11.574781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [06:31<00:00, 11.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-04 23:04:48.607024\n",
      "===== ANN =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.91      0.96      0.94   7526151\n",
      "         DoS       0.80      0.61      0.69   1792167\n",
      "       Mirai       1.00      1.00      1.00    583677\n",
      "       Recon       0.76      0.61      0.68     78630\n",
      "    Spoofing       0.75      0.73      0.74    107798\n",
      "      Benign       0.84      0.92      0.88    243322\n",
      "         Web       0.87      0.03      0.06      5433\n",
      "  BruteForce       0.99      0.14      0.25      2983\n",
      "\n",
      "    accuracy                           0.90  10340161\n",
      "   macro avg       0.86      0.63      0.65  10340161\n",
      "weighted avg       0.89      0.90      0.89  10340161\n",
      "\n",
      "Accuracy  : 0.8973367049120415\n",
      "Precision : 0.8926709583323498\n",
      "f1Score : 0.8916564773116894\n",
      "[[7259520  265074     767     617     140      32       1       0]\n",
      " [ 705053 1086073     368     614      28      31       0       0]\n",
      " [   1880     685  580892     157      57       6       0       0]\n",
      " [    931     661     183   48268    9768   18814       3       2]\n",
      " [     35      29      21    6506   78688   22500      19       0]\n",
      " [      8      22       7    5289   13425  224569       0       2]\n",
      " [      0       1       6    1216    2430    1615     165       0]\n",
      " [      6       0       0     891     753     901       1     431]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [05:17<00:00,  9.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-04 23:10:31.066860\n",
      "===== RF =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.99      1.00      1.00   7526151\n",
      "         DoS       1.00      1.00      1.00   1792167\n",
      "       Mirai       1.00      1.00      1.00    583677\n",
      "       Recon       0.96      0.63      0.76     78630\n",
      "    Spoofing       0.93      0.75      0.83    107798\n",
      "      Benign       0.93      0.93      0.93    243322\n",
      "         Web       0.74      0.02      0.04      5433\n",
      "  BruteForce       1.00      0.00      0.00      2983\n",
      "\n",
      "    accuracy                           0.99  10340161\n",
      "   macro avg       0.94      0.67      0.70  10340161\n",
      "weighted avg       0.99      0.99      0.99  10340161\n",
      "\n",
      "Accuracy  : 0.9918694689570114\n",
      "Precision : 0.991555352342272\n",
      "f1Score : 0.9910150172375725\n",
      "[[7525630     394       6      67      46       8       0       0]\n",
      " [   1595 1790560       5       1       5       1       0       0]\n",
      " [   1528       5  582137       0       7       0       0       0]\n",
      " [  19189       1       0   49510    2227    7684      19       0]\n",
      " [  16300       1       1     941   81204    9331      20       0]\n",
      " [  13687       1       0     540    2162  226930       2       0]\n",
      " [   3520       0       0     199    1237     360     117       0]\n",
      " [   2425       0       0     169      68     318       1       2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [01:38<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-04 23:12:33.389399\n",
      "===== LR =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.81      0.99      0.89   7526151\n",
      "         DoS       0.66      0.05      0.09   1792167\n",
      "       Mirai       0.98      0.99      0.98    583677\n",
      "       Recon       0.52      0.39      0.45     78630\n",
      "    Spoofing       0.69      0.32      0.44    107798\n",
      "      Benign       0.66      0.83      0.74    243322\n",
      "         Web       0.00      0.00      0.00      5433\n",
      "  BruteForce       0.00      0.00      0.00      2983\n",
      "\n",
      "    accuracy                           0.81  10340161\n",
      "   macro avg       0.54      0.45      0.45  10340161\n",
      "weighted avg       0.79      0.81      0.75  10340161\n",
      "\n",
      "Accuracy  : 0.8122512792595783\n",
      "Precision : 0.7866618237630673\n",
      "f1Score : 0.7467764438438975\n",
      "[[7464511   29737    2411    6806    5413   17273       0       0]\n",
      " [1694710   90447     121    2412     438    4039       0       0]\n",
      " [   1909    2743  575350     436     592    2647       0       0]\n",
      " [  12797    3938      92   30804    1166   29833       0       0]\n",
      " [  10973    4650    6242    4550   34729   46654       0       0]\n",
      " [  13801    5486    1066   12423    7578  202968       0       0]\n",
      " [    689     447     190     871     182    3054       0       0]\n",
      " [    306     133       2     968     101    1473       0       0]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Last ran on {len(ML_Models)} models, with {len(test_sets)} testing sets on date: {datetime.datetime.now()}\")\n",
    "for i in range(len(ML_Models)):\n",
    "    testModel(ML_Models[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====For debug ===\n",
    "# test_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')] \n",
    "#testModel(load_model(\"SavedModels\\\\BestANN.keras\"), \"Best ANN so far\")\n",
    "#testModel(Model(joblib.load(\"SavedModels/BestRF.pkl\"),\"debug_DF\", TYPES['SK_RF']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SK'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[146], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m==\u001b[39mTYPES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModels\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m==\u001b[39m\u001b[43mTYPES\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m      6\u001b[0m     joblib\u001b[38;5;241m.\u001b[39mdump(model\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "\u001b[1;31mKeyError\u001b[0m: 'SK'"
     ]
    }
   ],
   "source": [
    "for i in range(len(ML_Models)):\n",
    "    model = ML_Models[i]\n",
    "    if model.type==TYPES[\"TF\"]:\n",
    "        model.model.save(f\"SavedModels\\\\{model.name}.keras\",overwrite=True)\n",
    "    elif model.type==TYPES[\"SK_RF\"] or model.type==TYPES[\"SK_LR\"]:\n",
    "        joblib.dump(model.model, f\"SavedModels/{model.name}.pkl\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
