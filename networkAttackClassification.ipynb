{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# import tensorflow_decision_forests as tfdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorize and enumerate all attacks in dataset\n",
    "ATTACKS = ['DDoS', 'DoS', 'Mirai', 'Recon', 'Spoofing', 'Benign', 'Web', 'BruteForce']\n",
    "ATTACKS_ENUM = Enum('ATTACKS', ATTACKS, start=0)\n",
    "dict_7classes = {}\n",
    "dict_7classes['DDoS-RSTFINFlood'] = 'DDoS'\n",
    "dict_7classes['DDoS-PSHACK_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SYN_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-TCP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SynonymousIP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ACK_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-SlowLoris'] = 'DDoS'\n",
    "dict_7classes['DDoS-HTTP_Flood'] = 'DDoS'\n",
    "\n",
    "dict_7classes['DoS-UDP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-SYN_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-TCP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-HTTP_Flood'] = 'DoS'\n",
    "\n",
    "\n",
    "dict_7classes['Mirai-greeth_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-greip_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-udpplain'] = 'Mirai'\n",
    "\n",
    "dict_7classes['Recon-PingSweep'] = 'Recon'\n",
    "dict_7classes['Recon-OSScan'] = 'Recon'\n",
    "dict_7classes['Recon-PortScan'] = 'Recon'\n",
    "dict_7classes['VulnerabilityScan'] = 'Recon'\n",
    "dict_7classes['Recon-HostDiscovery'] = 'Recon'\n",
    "\n",
    "dict_7classes['DNS_Spoofing'] = 'Spoofing'\n",
    "dict_7classes['MITM-ArpSpoofing'] = 'Spoofing'\n",
    "\n",
    "dict_7classes['BenignTraffic'] = 'Benign'\n",
    "\n",
    "dict_7classes['BrowserHijacking'] = 'Web'\n",
    "dict_7classes['Backdoor_Malware'] = 'Web'\n",
    "dict_7classes['XSS'] = 'Web'\n",
    "dict_7classes['Uploading_Attack'] = 'Web'\n",
    "dict_7classes['SqlInjection'] = 'Web'\n",
    "dict_7classes['CommandInjection'] = 'Web'\n",
    "\n",
    "\n",
    "dict_7classes['DictionaryBruteForce'] = 'BruteForce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====Split Train / Test data======\n",
    "# Dataset link-> https://www.unb.ca/cic/datasets/iotdataset-2023.html\n",
    "#E. C. P. Neto, S. Dadkhah, R. Ferreira, A. Zohourian, R. Lu, A. A. Ghorbani. \"CICIoT2023: A real-time dataset and benchmark for large-scale attacks in IoT environment,\" Sensor (2023) – (submitted to Journal of Sensors).\n",
    "\n",
    "DATASET_DIRECTORY = 'dataset/'\n",
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')] # all files\n",
    "#df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('1-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')] # smaller subset for faster testing, 17 files =  10% of whole dataset\n",
    "#df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('11-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')] # 2 files = 1%\n",
    "df_sets.sort()\n",
    "training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "test_sets = df_sets[int(len(df_sets)*.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Extract Data=====\n",
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "       'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "       'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "       'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "       'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "       'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "       'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "] #columns 0-45\n",
    "Y_columns = 'label' #column 46\n",
    "\n",
    "all_columns = X_columns+[Y_columns]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "      'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "      'Rate', 'Srate', 'Drate', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "      'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "      'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "]\n",
    "CATEGORICAL_FEATURE_NAMES = [\n",
    "      'fin_flag_number', 'syn_flag_number',\n",
    "      'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "      'ece_flag_number', 'cwr_flag_number','HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "      'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [03:53<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "#=====Feature Scaling======\n",
    "# columnsToScale = ['flow_duration', 'Header_Length', 'Duration', 'Rate', 'Srate', 'Drate', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'fin_count']\n",
    "# scale all\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "for train_set in tqdm(training_sets):\n",
    "    df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[X_columns]\n",
    "    x_train = scaler.fit(df)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 0, 10, 512\n",
    "activationFunction='relu'\n",
    "\n",
    "# def getOtimizedSequentialModel():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(46, activation=activationFunction))\n",
    "#     model.add(Dense(30, activation=activationFunction))\n",
    "#     model.add(Dense(8, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return model\n",
    "\n",
    "def getManyLayersModel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(46, activation=activationFunction))\n",
    "    model.add(Dense(30, activation=activationFunction))\n",
    "    model.add(Dense(20, activation=activationFunction))\n",
    "    model.add(Dense(12, activation=activationFunction))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                    metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "                    )\n",
    "    return model\n",
    "\n",
    "# def getMoreLayersModel():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(46, activation=activationFunction))\n",
    "#     model.add(Dense(32, activation=activationFunction))\n",
    "#     model.add(Dense(22, activation=activationFunction))\n",
    "#     model.add(Dense(15, activation=activationFunction))\n",
    "#     model.add(Dense(10, activation=activationFunction))\n",
    "#     model.add(Dense(8, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return model\n",
    "\n",
    "def getManyLayersModel1024():\n",
    "    batch_size =  1024\n",
    "    model = Sequential()\n",
    "    model.add(Dense(46, activation=activationFunction))\n",
    "    model.add(Dense(30, activation=activationFunction))\n",
    "    model.add(Dense(20, activation=activationFunction))\n",
    "    model.add(Dense(12, activation=activationFunction))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                    metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "                    )\n",
    "    return model\n",
    "\n",
    "def getManyLayersModel64():\n",
    "    batch_size =  64\n",
    "    model = Sequential()\n",
    "    model.add(Dense(46, activation=activationFunction))\n",
    "    model.add(Dense(30, activation=activationFunction))\n",
    "    model.add(Dense(20, activation=activationFunction))\n",
    "    model.add(Dense(12, activation=activationFunction))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                    metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "                    )\n",
    "    return model\n",
    "\n",
    "# def getSeluModel():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(46, activation='selu'))\n",
    "#     model.add(Dense(30, activation='selu'))\n",
    "#     model.add(Dense(20, activation='selu'))\n",
    "#     model.add(Dense(12, activation='selu'))\n",
    "#     model.add(Dense(8, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return model\n",
    "\n",
    "ML_Models = [\n",
    "            getManyLayersModel(),\n",
    "            getManyLayersModel1024(),\n",
    "            getManyLayersModel64(),\n",
    "            # getThirdModel(),\n",
    "            # getFourthModel()\n",
    "\n",
    "]\n",
    "ML_Model_Names = [\n",
    "            'ManyLayers512',\n",
    "            'ManyLayers1024',\n",
    "            'ManyLayers64',\n",
    "            'Fourth'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ran on 3 models, with 135 training sets on date: 2024-05-30 22:25:31.991232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [14:13:17<00:00, 379.24s/it]  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Last ran on {len(ML_Models)} models, with {len(training_sets)} training sets on date: {datetime.datetime.now()}\")\n",
    "for train_set in tqdm(training_sets):\n",
    "    df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "    x_train = scaler.transform(df[X_columns])\n",
    "    y_train = to_categorical([ATTACKS_ENUM[dict_7classes[k]].value for k in df[Y_columns]], num_classes=8)\n",
    "\n",
    "    for model in ML_Models:\n",
    "            model.fit(x=x_train, \n",
    "                        y=y_train, \n",
    "                        epochs=epochs, \n",
    "                        verbose=verbose,\n",
    "                        batch_size=batch_size)                   \n",
    "    del df\n",
    "    del x_train\n",
    "    del y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a seperate model to detect each attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose, epochs, batch_size = 1, 100, 512\n",
    "# activationFunction='relu'\n",
    "\n",
    "# def getSequentialModel():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(128, activation=activationFunction))\n",
    "#     model.add(Dense(64, activation=activationFunction))\n",
    "#     model.add(Dense(32, activation=activationFunction))\n",
    "#     model.add(Dense(16, activation=activationFunction))\n",
    "#     model.add(Dense(8, activation=activationFunction))\n",
    "#     model.add(Dense(4, activation=activationFunction))\n",
    "#     model.add(Dense(2, activation='softmax'))\n",
    "#     model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "#                     optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "#                     metrics=[ keras.metrics.BinaryAccuracy(), keras.metrics.FalseNegatives()]\n",
    "#                     )\n",
    "#     return model\n",
    "\n",
    "# ML_Models = [\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel(),\n",
    "#             getSequentialModel()\n",
    "\n",
    "# ]\n",
    "# ML_Model_Names = ATTACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Last ran on {len(ML_Models)} models, with {len(training_sets)} training sets on date: {datetime.datetime.now()}\")\n",
    "# for train_set in tqdm(training_sets):\n",
    "#     df = pd.read_csv(DATASET_DIRECTORY + train_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#     x_train = scaler.transform(df[X_columns])\n",
    "\n",
    "#     for i in range(len(ML_Models)-1):\n",
    "#             y_train = to_categorical([ATTACKS_ENUM[dict_7classes[k]].value == ATTACKS_ENUM[ATTACKS[i]].value for k in df[Y_columns]], num_classes=2)\n",
    "#             model = ML_Models[i]\n",
    "#             model.fit(x=x_train, \n",
    "#                         y=y_train, \n",
    "#                         epochs=epochs, \n",
    "#                         verbose=verbose,\n",
    "#                         batch_size=batch_size)   \n",
    "#             del y_train             \n",
    "#     del df\n",
    "#     del x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def showResults8Models(test, pred, model_num):\n",
    "#     print(f\"===== {model_num} =====\")\n",
    "#     print(classification_report(test, pred, target_names=[\"Negative\", \"Positive\"]))\n",
    "#     accuracy = accuracy_score(test, pred)\n",
    "#     precision=precision_score(test, pred, average='weighted')\n",
    "#     f1Score=f1_score(test, pred, average='weighted') \n",
    "#     print(\"Accuracy  : {}\".format(accuracy))\n",
    "#     print(\"Precision : {}\".format(precision))\n",
    "#     print(\"f1Score : {}\".format(f1Score))\n",
    "#     cm=confusion_matrix(test, pred)\n",
    "#     print(cm) \n",
    "\n",
    "# print(f\"Last ran on {len(ML_Models)} models, with {len(test_sets)} testing sets on date: {datetime.datetime.now()}\")\n",
    "# for i in range(len(ML_Models)):\n",
    "#     model = ML_Models[i]\n",
    "#     y_test = []\n",
    "#     y_predict = []\n",
    "#     for test_set in tqdm(test_sets):\n",
    "#         df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "#         x_test = scaler.transform(df[X_columns])\n",
    "#         for k in df[Y_columns]:\n",
    "#             y_test.append(ATTACKS_ENUM[dict_7classes[k]].value==ATTACKS[i])\n",
    "#         y_predict+= list(model.predict(x_test))\n",
    "\n",
    "#         del df\n",
    "#         del x_test\n",
    "\n",
    "#     myarr = np.array([ATTACKS_ENUM[dict_7classes[k]].value == ATTACKS_ENUM[ATTACKS[0]].value for k in ['DDoS-RSTFINFlood','DDoS-PSHACK_Flood','DDoS-SYN_Flood','DoS-SYN_Flood','DoS-TCP_Flood','Mirai-udpplain','Recon-OSScan','DNS_Spoofing','BrowserHijacking','Backdoor_Malware','DictionaryBruteForce']])\n",
    "#     print(myarr)\n",
    "#     print(to_categorical(myarr, num_classes=2))\n",
    "#     y_test=np.array(y_test)\n",
    "#     print(y_test[0:10])\n",
    "#     y_test = to_categorical(y_test, num_classes=2)\n",
    "#     print(y_test[0:10])\n",
    "#     print(\"=========\")\n",
    "#     for i in range(10):\n",
    "#         print(f\"{i}: {y_predict[i]} actual {y_test[i]}\")    \n",
    "\n",
    "#     test = np.argmax(y_test, axis=1)\n",
    "#     predict = np.argmax(y_predict, axis=1)\n",
    "#     showResults8Models(test, predict, i)\n",
    "\n",
    "#     del test\n",
    "#     del predict\n",
    "#     del y_test\n",
    "#     del y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the resulting trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveOutput(output, model_name):\n",
    "    savepath = f\"\\outputs\\{model_name}.txt\"\n",
    "    output=output\n",
    "    %store output >>\"\\outputs\\{}.txt\".format(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResults(test, pred,model_name):\n",
    "    output = ''\n",
    "    output += str(datetime.datetime.now())\n",
    "    output += f\"\\n===== {model_name} =====\\n\"\n",
    "    output+=classification_report(test, pred, target_names=ATTACKS)\n",
    "    accuracy = accuracy_score(test, pred)\n",
    "    precision=precision_score(test, pred, average='weighted')\n",
    "    f1Score=f1_score(test, pred, average='weighted') \n",
    "    output+=f\"\\nAccuracy  : {accuracy}\\n\"\n",
    "    output+=f\"Precision : {precision}\\n\"\n",
    "    output+=f\"f1Score : {f1Score}\\n\"\n",
    "    cm=confusion_matrix(test, pred)\n",
    "    output+=str(cm) \n",
    "    try:\n",
    "        %store output >>\"outputs\\output.txt\"\n",
    "    except Exception as e:\n",
    "        print(\"error saving to file\")\n",
    "        print(e)\n",
    "\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ran on 3 models, with 34 testing sets on date: 2024-05-31 12:38:49.809368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [07:44<00:00, 13.67s/it]\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'output' (str) to file 'outputs\\output.txt'.\n",
      "2024-05-31 12:46:39.361720\n",
      "===== MoreLayers_softmax =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.76      1.00      0.86   7526151\n",
      "         DoS       0.00      0.00      0.00   1792167\n",
      "       Mirai       0.00      0.00      0.00    583677\n",
      "       Recon       0.00      0.00      0.00     78630\n",
      "    Spoofing       0.57      0.70      0.62    107798\n",
      "      Benign       0.79      0.96      0.87    243322\n",
      "         Web       0.00      0.00      0.00      5433\n",
      "  BruteForce       0.00      0.00      0.00      2983\n",
      "\n",
      "    accuracy                           0.76  10340161\n",
      "   macro avg       0.26      0.33      0.29  10340161\n",
      "weighted avg       0.58      0.76      0.66  10340161\n",
      "\n",
      "Accuracy  : 0.7577108325489322\n",
      "Precision : 0.5771490704479015\n",
      "f1Score : 0.6551848003301307\n",
      "[[7525649       0       0       0     380     122       0       0]\n",
      " [1792036       0       0       0      89      42       0       0]\n",
      " [ 583626       0       0       0      44       7       0       0]\n",
      " [   8226       0       0       0   43877   26527       0       0]\n",
      " [    335       0       0       0   74991   32472       0       0]\n",
      " [     72       0       0       0    9038  234212       0       0]\n",
      " [      4       0       0       0    2740    2689       0       0]\n",
      " [     37       0       0       0    1307    1639       0       0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [06:13<00:00, 10.99s/it]\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'output' (str) to file 'outputs\\output.txt'.\n",
      "2024-05-31 12:53:17.276191\n",
      "===== ManyLayers_nosoftmax =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.83      1.00      0.90   7526151\n",
      "         DoS       0.99      0.13      0.22   1792167\n",
      "       Mirai       1.00      0.99      1.00    583677\n",
      "       Recon       0.81      0.48      0.61     78630\n",
      "    Spoofing       0.72      0.74      0.73    107798\n",
      "      Benign       0.83      0.93      0.88    243322\n",
      "         Web       0.00      0.00      0.00      5433\n",
      "  BruteForce       0.00      0.00      0.00      2983\n",
      "\n",
      "    accuracy                           0.84  10340161\n",
      "   macro avg       0.65      0.53      0.54  10340161\n",
      "weighted avg       0.86      0.84      0.79  10340161\n",
      "\n",
      "Accuracy  : 0.8389115024417898\n",
      "Precision : 0.8633217348399608\n",
      "f1Score : 0.7866758474282635\n",
      "[[7524154    1686      37     177      77      20       0       0]\n",
      " [1565604  226406      70      62      23       2       0       0]\n",
      " [   4223      75  579362       7       9       1       0       0]\n",
      " [   8264      22       2   37960   13249   19133       0       0]\n",
      " [    125      16       5    3694   80121   23837       0       0]\n",
      " [    100       1       6    3297   13441  226477       0       0]\n",
      " [     15       0       0     785    3018    1615       0       0]\n",
      " [      6       0       0     672    1322     983       0       0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [06:39<00:00, 11.74s/it]\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\varte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'output' (str) to file 'outputs\\output.txt'.\n",
      "2024-05-31 13:00:21.613127\n",
      "===== Selu_softmax =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.88      0.99      0.93   7526151\n",
      "         DoS       0.92      0.44      0.59   1792167\n",
      "       Mirai       1.00      0.99      1.00    583677\n",
      "       Recon       0.78      0.53      0.63     78630\n",
      "    Spoofing       0.89      0.60      0.72    107798\n",
      "      Benign       0.77      0.97      0.86    243322\n",
      "         Web       0.00      0.00      0.00      5433\n",
      "  BruteForce       0.95      0.07      0.13      2983\n",
      "\n",
      "    accuracy                           0.89  10340161\n",
      "   macro avg       0.77      0.58      0.61  10340161\n",
      "weighted avg       0.89      0.89      0.87  10340161\n",
      "\n",
      "Accuracy  : 0.8866587280410818\n",
      "Precision : 0.8906858100138404\n",
      "f1Score : 0.8702960423312883\n",
      "[[7461882   63422      66     703      11      65       0       2]\n",
      " [1009351  782159      83     554       5      15       0       0]\n",
      " [   2640     740  579806     463      24       4       0       0]\n",
      " [   4107     517       3   41937    3773   28290       0       3]\n",
      " [     64      20      92    5655   65063   36904       0       0]\n",
      " [     53      12       3    2955    3155  237137       0       7]\n",
      " [      0       1       0    1104    1073    3255       0       0]\n",
      " [    231       3       0     517     216    1806       0     210]]\n"
     ]
    }
   ],
   "source": [
    "def testModel(model, model_name):\n",
    "    y_test = []\n",
    "    y_predict = []\n",
    "    for test_set in tqdm(test_sets):\n",
    "        df = pd.read_csv(DATASET_DIRECTORY + test_set, index_col=None, header=0, delimiter=',')[all_columns]\n",
    "        x_test = scaler.transform(df[X_columns])\n",
    "        for k in df[Y_columns]:\n",
    "            y_test.append(ATTACKS_ENUM[dict_7classes[k]].value)\n",
    "        y_predict+= list(model.predict(x_test, verbose=0))\n",
    "\n",
    "        del df\n",
    "        del x_test\n",
    "\n",
    "    y_test=np.array(y_test)\n",
    "    y_test = to_categorical(y_test, num_classes=8)\n",
    "    test = np.argmax(y_test, axis=1)\n",
    "    predict = np.argmax(y_predict, axis=1)\n",
    "    showResults(test, predict, model_name)\n",
    "\n",
    "    del test\n",
    "    del predict\n",
    "    del y_test\n",
    "    del y_predict\n",
    "\n",
    "print(f\"Last ran on {len(ML_Models)} models, with {len(test_sets)} testing sets on date: {datetime.datetime.now()}\")\n",
    "for i in range(len(ML_Models)):\n",
    "    testModel(ML_Models[i],ML_Model_Names[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====For debug ===\n",
    "# test_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')] \n",
    "# testModel(load_model(\"SavedModels\\\\ManyLayers.keras\"), \"ManyLayers from file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ML_Models)):\n",
    "    ML_Models[i].save(f\"SavedModels\\\\{ML_Model_Names[i]}.keras\",overwrite=True)\n",
    "    #del ML_Models[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Maximum number of decision trees. The effective number of trained trees can be smaller if early stopping is enabled.\n",
    "# NUM_TREES = 250\n",
    "# # Minimum number of examples in a node.\n",
    "# MIN_EXAMPLES = 6\n",
    "# # Maximum depth of the tree. max_depth=1 means that all trees will be roots.\n",
    "# MAX_DEPTH = 5\n",
    "# # Ratio of the dataset (sampling without replacement) used to train individual trees for the random sampling method.\n",
    "# SUBSAMPLE = 0.65\n",
    "# # Control the sampling of the datasets used to train individual trees.\n",
    "# SAMPLING_METHOD = \"RANDOM\"\n",
    "# # Ratio of the training dataset used to monitor the training. Require to be >0 if early stopping is enabled.\n",
    "# VALIDATION_RATIO = 0.1\n",
    "\n",
    "# epochs_df = 100\n",
    "# batch_size_df = 512\n",
    "# verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def specify_feature_usages():\n",
    "#     feature_usages = []\n",
    "\n",
    "#     for feature_name in NUMERIC_FEATURE_NAMES:\n",
    "#         feature_usage = tfdf.keras.FeatureUsage(\n",
    "#             name=feature_name, semantic=tfdf.keras.FeatureSemantic.NUMERICAL\n",
    "#         )\n",
    "#         feature_usages.append(feature_usage)\n",
    "\n",
    "#     for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "#         feature_usage = tfdf.keras.FeatureUsage(\n",
    "#             name=feature_name, semantic=tfdf.keras.FeatureSemantic.CATEGORICAL\n",
    "#         )\n",
    "#         feature_usages.append(feature_usage)\n",
    "\n",
    "#     return feature_usages\n",
    "\n",
    "\n",
    "# def create_gbt_model():\n",
    "#     # See all the model parameters in https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/GradientBoostedTreesModel\n",
    "#     gbt_model = tfdf.keras.GradientBoostedTreesModel(\n",
    "#         features=specify_feature_usages(),\n",
    "#         exclude_non_specified_features=True,\n",
    "#         num_trees=NUM_TREES,\n",
    "#         max_depth=MAX_DEPTH,\n",
    "#         min_examples=MIN_EXAMPLES,\n",
    "#         subsample=SUBSAMPLE,\n",
    "#         validation_ratio=VALIDATION_RATIO,\n",
    "#         task=tfdf.keras.Task.CLASSIFICATION,\n",
    "#     )\n",
    "\n",
    "#     gbt_model.compile(metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")])\n",
    "#     return gbt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tfdf.keras.RandomForestModel()\n",
    "# for train_set in tqdm(training_sets):\n",
    "#     tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(train_set,label=\"species\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #======== Cross Validation ===========\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "# skf.get_n_splits(xTrain, yTrain)\n",
    "# foldNum=0\n",
    "# for train_index, val_index in skf.split(xTrain, yTrain):\n",
    "#     foldNum+=1\n",
    "#     print(\"Results for fold\",foldNum)\n",
    "#     X_train, X_val = X[train_index], X[val_index]\n",
    "#     Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "    \n",
    "#     # one hot encode\n",
    "#     Y_train = to_categorical(Y_train)\n",
    "#     Y_val = to_categorical(Y_val)\n",
    "    \n",
    "#     history = model.fit(X_train, Y_train, \n",
    "#                         validation_data = (X_val, Y_val), \n",
    "#                         epochs=epochs, \n",
    "#                         batch_size=batch_size)  \n",
    "#     yPredict = model.predict(X_val)\n",
    "\n",
    "#     #Converting one hot encoded test label to label    \n",
    "#     pred = np.argmax(yPredict, axis=1)\n",
    "#     val = np.argmax(Y_val, axis=1)\n",
    "    \n",
    "#     showResults(val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============Test Phase============\n",
    "# yPred = model.predict(xTest)\n",
    "# yTest = to_categorical(yTest)\n",
    "# pred = np.argmax(yPred, axis=1)\n",
    "# test = np.argmax(yTest, axis=1)\n",
    "# showResults(test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
